[
  {
    "id": "ac6vczyqbvza3p71dkwi66f8",
    "courseId": "i4bljpjc2vktsmwgynhzi84e",
    "title": "Lesson 1: Fundamentals of Observability - Part 1",
    "slug": "lesson-1",
    "description": "In this lesson, we'll cover important concepts related to Fundamentals of Observability",
    "type": "video",
    "content": "# Lesson 1 Content\n\nThis is the content for lesson 1...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.291Z",
    "updatedAt": "2025-05-30T06:43:34.291Z"
  },
  {
    "id": "ql3bdfugveolanci8zxovb53",
    "courseId": "i4bljpjc2vktsmwgynhzi84e",
    "title": "Lesson 2: Fundamentals of Observability - Part 2",
    "slug": "lesson-2",
    "description": "In this lesson, we'll cover important concepts related to Fundamentals of Observability",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-i4bljpjc2vktsmwgynhzi84e-lesson-2",
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.364Z",
    "updatedAt": "2025-05-30T06:43:34.364Z"
  },
  {
    "id": "hksbtmg7n1jfqfgrryo920ux",
    "courseId": "i4bljpjc2vktsmwgynhzi84e",
    "title": "Lesson 3: Fundamentals of Observability - Part 3",
    "slug": "lesson-3",
    "description": "In this lesson, we'll cover important concepts related to Fundamentals of Observability",
    "type": "text",
    "content": "# Lesson 3 Content\n\nThis is the content for lesson 3...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.435Z",
    "updatedAt": "2025-05-30T06:43:34.435Z"
  },
  {
    "id": "b0amyr5ik01gk1u6s6dv6dtm",
    "courseId": "qxo6zp4wkwo5ie7c032wb4a6",
    "title": "Lesson 1: Advanced Error Tracking - Part 1",
    "slug": "lesson-1",
    "description": "In this lesson, we'll cover important concepts related to Advanced Error Tracking",
    "type": "video",
    "content": "# Lesson 1 Content\n\nThis is the content for lesson 1...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.575Z",
    "updatedAt": "2025-05-30T06:43:34.575Z"
  },
  {
    "id": "h63nwt5r0ye6i48906ylp16m",
    "courseId": "qxo6zp4wkwo5ie7c032wb4a6",
    "title": "Lesson 2: Advanced Error Tracking - Part 2",
    "slug": "lesson-2",
    "description": "In this lesson, we'll cover important concepts related to Advanced Error Tracking",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-qxo6zp4wkwo5ie7c032wb4a6-lesson-2",
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.648Z",
    "updatedAt": "2025-05-30T06:43:34.648Z"
  },
  {
    "id": "m7hn8qsj7l6u0i0k4pkpzx33",
    "courseId": "qxo6zp4wkwo5ie7c032wb4a6",
    "title": "Lesson 3: Advanced Error Tracking - Part 3",
    "slug": "lesson-3",
    "description": "In this lesson, we'll cover important concepts related to Advanced Error Tracking",
    "type": "text",
    "content": "# Lesson 3 Content\n\nThis is the content for lesson 3...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.720Z",
    "updatedAt": "2025-05-30T06:43:34.720Z"
  },
  {
    "id": "h9yb7swq1sex5eyxduvnzybz",
    "courseId": "qxo6zp4wkwo5ie7c032wb4a6",
    "title": "Lesson 4: Advanced Error Tracking - Part 4",
    "slug": "lesson-4",
    "description": "In this lesson, we'll cover important concepts related to Advanced Error Tracking",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-qxo6zp4wkwo5ie7c032wb4a6-lesson-4",
    "duration": "45 min",
    "order": 4,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.789Z",
    "updatedAt": "2025-05-30T06:43:34.789Z"
  },
  {
    "id": "qvjbegd1dcw92kbjtpia4je7",
    "courseId": "qxo6zp4wkwo5ie7c032wb4a6",
    "title": "Lesson 5: Advanced Error Tracking - Part 5",
    "slug": "lesson-5",
    "description": "In this lesson, we'll cover important concepts related to Advanced Error Tracking",
    "type": "text",
    "content": "# Lesson 5 Content\n\nThis is the content for lesson 5...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 5,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:34.862Z",
    "updatedAt": "2025-05-30T06:43:34.862Z"
  },
  {
    "id": "r504a9phn93qnfvbdzy1if88",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 1: Performance Optimization Techniques - Part 1",
    "slug": "lesson-1",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "video",
    "content": "# Lesson 1 Content\n\nThis is the content for lesson 1...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.002Z",
    "updatedAt": "2025-05-30T06:43:35.002Z"
  },
  {
    "id": "onh1qsm3it62s98teokjwxwc",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 2: Performance Optimization Techniques - Part 2",
    "slug": "lesson-2",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-sjeg5c66ykczldek4feh7ddq-lesson-2",
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.073Z",
    "updatedAt": "2025-05-30T06:43:35.073Z"
  },
  {
    "id": "xile7wfrj87mo3tts21nczc6",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 3: Performance Optimization Techniques - Part 3",
    "slug": "lesson-3",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "text",
    "content": "# Lesson 3 Content\n\nThis is the content for lesson 3...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.145Z",
    "updatedAt": "2025-05-30T06:43:35.145Z"
  },
  {
    "id": "fmolkkdo4c5uyt42p76tbei4",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 4: Performance Optimization Techniques - Part 4",
    "slug": "lesson-4",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-sjeg5c66ykczldek4feh7ddq-lesson-4",
    "duration": "45 min",
    "order": 4,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.214Z",
    "updatedAt": "2025-05-30T06:43:35.214Z"
  },
  {
    "id": "onhwpwbge4i0hvbrhovk5ne0",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 5: Performance Optimization Techniques - Part 5",
    "slug": "lesson-5",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "text",
    "content": "# Lesson 5 Content\n\nThis is the content for lesson 5...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 5,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.285Z",
    "updatedAt": "2025-05-30T06:43:35.285Z"
  },
  {
    "id": "qrm4uhxa7wcgzwxo4ynqxf5e",
    "courseId": "sjeg5c66ykczldek4feh7ddq",
    "title": "Lesson 6: Performance Optimization Techniques - Part 6",
    "slug": "lesson-6",
    "description": "In this lesson, we'll cover important concepts related to Performance Optimization Techniques",
    "type": "video",
    "content": null,
    "videoUrl": "https://example.com/videos/course-sjeg5c66ykczldek4feh7ddq-lesson-6",
    "duration": "45 min",
    "order": 6,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-05-30T06:43:35.360Z",
    "updatedAt": "2025-05-30T06:43:35.360Z"
  },
  {
    "id": "tltxkztaseg8ss788oonixqd",
    "courseId": "tnjj7w0a4emouvg79hko7tud",
    "title": "Introduction to Distributed Tracing Systems",
    "slug": "introduction-to-distributed-tracing-systems",
    "description": "Get started with Distributed Tracing Systems",
    "type": "text",
    "content": "# Introduction to Distributed Tracing Systems\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.044Z",
    "updatedAt": "2025-06-02T06:34:15.044Z"
  },
  {
    "id": "dwu5sb55gfo16v8f1zzj803d",
    "courseId": "tnjj7w0a4emouvg79hko7tud",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Core Concepts\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.117Z",
    "updatedAt": "2025-06-02T06:34:15.117Z"
  },
  {
    "id": "zfmdonw0aotcsgze8cnr4k50",
    "courseId": "tnjj7w0a4emouvg79hko7tud",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Practical Implementation\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.188Z",
    "updatedAt": "2025-06-02T06:34:15.188Z"
  },
  {
    "id": "f5v9q0me9t7qtvs1ogdozgf6",
    "courseId": "fhkzmu9thkgi9fcrn6r7yhr7",
    "title": "Introduction to Frontend Error Monitoring",
    "slug": "introduction-to-frontend-error-monitoring",
    "description": "Get started with Frontend Error Monitoring",
    "type": "text",
    "content": "# Introduction to Frontend Error Monitoring\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.405Z",
    "updatedAt": "2025-06-02T06:34:15.405Z"
  },
  {
    "id": "sjgicyl8l9mv99cefxtawspe",
    "courseId": "fhkzmu9thkgi9fcrn6r7yhr7",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Core Concepts\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.480Z",
    "updatedAt": "2025-06-02T06:34:15.480Z"
  },
  {
    "id": "nkuj27hjfyu5lbaqf0w296qz",
    "courseId": "fhkzmu9thkgi9fcrn6r7yhr7",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Practical Implementation\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.555Z",
    "updatedAt": "2025-06-02T06:34:15.555Z"
  },
  {
    "id": "tp9tqlr9it5yqwys732sksca",
    "courseId": "wnuh4id6xxitp3dl96dkovnh",
    "title": "Introduction to Log Analysis and Visualization",
    "slug": "introduction-to-log-analysis-and-visualization",
    "description": "Get started with Log Analysis and Visualization",
    "type": "text",
    "content": "# Introduction to Log Analysis and Visualization\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:15.951Z",
    "updatedAt": "2025-06-02T06:34:15.951Z"
  },
  {
    "id": "ajkyburtar9barvy8zw1tcfb",
    "courseId": "wnuh4id6xxitp3dl96dkovnh",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Core Concepts\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.022Z",
    "updatedAt": "2025-06-02T06:34:16.022Z"
  },
  {
    "id": "wz9xos336mdvcug9be6p13zj",
    "courseId": "wnuh4id6xxitp3dl96dkovnh",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Practical Implementation\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.094Z",
    "updatedAt": "2025-06-02T06:34:16.094Z"
  },
  {
    "id": "bgijjtn50ndkl3f55tqksue5",
    "courseId": "va92g7yctjcxc5dnxqbhn86r",
    "title": "Introduction to Using Tracing and Spans for Performance",
    "slug": "introduction-to-using-tracing-and-spans-for-performance",
    "description": "Get started with Using Tracing and Spans for Performance",
    "type": "text",
    "content": "# Introduction to Using Tracing and Spans for Performance\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.026Z",
    "updatedAt": "2025-06-02T06:34:17.026Z"
  },
  {
    "id": "ultp7h1otue00cc2hdr5s1rx",
    "courseId": "va92g7yctjcxc5dnxqbhn86r",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Core Concepts\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.095Z",
    "updatedAt": "2025-06-02T06:34:17.095Z"
  },
  {
    "id": "rwon196vk6m58wa35g1352ip",
    "courseId": "va92g7yctjcxc5dnxqbhn86r",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Practical Implementation\n\nThis lesson content will be populated later.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.166Z",
    "updatedAt": "2025-06-02T06:34:17.166Z"
  },
  {
    "id": "aafewj5sz30i8ycod69asstw",
    "courseId": "znfssyl27ie0hm5j0d1ss70e",
    "title": "Introduction to Observability for AI applications",
    "slug": "introduction-to-observability-for-ai-applications",
    "description": "Get started with Observability for AI applications",
    "type": "text",
    "content": "# Introduction to AI Observability\n\n## Overview\nAI observability extends traditional application monitoring to address the unique challenges of artificial intelligence and machine learning systems. Unlike conventional software, AI systems involve complex data pipelines, model inference, and unpredictable behaviors that require specialized monitoring approaches.\n\n## Why AI Observability Matters\n\n### Unique Challenges in AI Systems\n- **Model Drift**: Performance degradation over time as real-world data diverges from training data\n- **Data Quality Issues**: Corrupted, biased, or incomplete input data affecting model accuracy\n- **Latency Sensitivity**: Real-time inference requirements with strict performance constraints\n- **Resource Intensity**: High computational costs requiring careful resource monitoring\n- **Explainability**: Understanding model decisions for compliance and debugging\n\n### Business Impact\n- **Revenue Protection**: Prevent model failures that could impact business operations\n- **Compliance**: Meet regulatory requirements for AI system transparency\n- **Cost Optimization**: Monitor and control expensive GPU and compute resources\n- **User Experience**: Ensure consistent, accurate AI-powered features\n\n## Key Components of AI Observability\n\n### 1. Model Performance Monitoring\nTrack model accuracy, precision, recall, and other performance metrics over time:\n\n```python\nimport sentry_sdk\nfrom sentry_sdk.integrations.logging import LoggingIntegration\n\n# Initialize Sentry for AI monitoring\nsentry_sdk.init(\n    dsn=\"YOUR_SENTRY_DSN\",\n    traces_sample_rate=1.0,\n    integrations=[LoggingIntegration()]\n)\n\ndef monitor_model_performance(model, test_data, predictions):\n    with sentry_sdk.start_transaction(name=\"model_performance_check\"):\n        accuracy = calculate_accuracy(test_data, predictions)\n        precision = calculate_precision(test_data, predictions)\n        recall = calculate_recall(test_data, predictions)\n        \n        # Log metrics to Sentry\n        sentry_sdk.set_tag(\"model_version\", model.version)\n        sentry_sdk.set_extra(\"accuracy\", accuracy)\n        sentry_sdk.set_extra(\"precision\", precision)\n        sentry_sdk.set_extra(\"recall\", recall)\n        \n        # Alert if performance drops below threshold\n        if accuracy < 0.85:\n            sentry_sdk.capture_message(\n                f\"Model accuracy dropped to {accuracy}\",\n                level=\"warning\"\n            )\n```\n\n### 2. Data Pipeline Monitoring\nMonitor data quality and pipeline health:\n\n```python\ndef monitor_data_pipeline(data_batch):\n    with sentry_sdk.start_transaction(name=\"data_pipeline_monitoring\"):\n        # Check data quality metrics\n        missing_values = data_batch.isnull().sum().sum()\n        duplicate_count = data_batch.duplicated().sum()\n        schema_violations = validate_schema(data_batch)\n        \n        # Log data quality metrics\n        sentry_sdk.set_extra(\"missing_values\", missing_values)\n        sentry_sdk.set_extra(\"duplicates\", duplicate_count)\n        sentry_sdk.set_extra(\"schema_violations\", schema_violations)\n        \n        # Alert on data quality issues\n        if missing_values > 100:\n            sentry_sdk.capture_message(\n                f\"High missing values detected: {missing_values}\",\n                level=\"error\"\n            )\n```\n\n### 3. Inference Monitoring\nTrack model inference performance and latency:\n\n```python\nimport time\n\ndef monitor_inference(model, input_data):\n    with sentry_sdk.start_transaction(name=\"model_inference\") as transaction:\n        start_time = time.time()\n        \n        try:\n            prediction = model.predict(input_data)\n            inference_time = time.time() - start_time\n            \n            # Log inference metrics\n            transaction.set_data(\"inference_time_ms\", inference_time * 1000)\n            transaction.set_data(\"input_shape\", input_data.shape)\n            transaction.set_data(\"prediction_confidence\", prediction.max())\n            \n            # Alert on slow inference\n            if inference_time > 0.5:  # 500ms threshold\n                sentry_sdk.capture_message(\n                    f\"Slow inference detected: {inference_time}s\",\n                    level=\"warning\"\n                )\n                \n            return prediction\n            \n        except Exception as e:\n            sentry_sdk.capture_exception(e)\n            raise\n```\n\n## AI Observability Architecture\n\n### Multi-Layer Monitoring Approach\n1. **Infrastructure Layer**: GPU utilization, memory usage, network I/O\n2. **Data Layer**: Data quality, pipeline health, feature drift\n3. **Model Layer**: Performance metrics, inference latency, prediction distribution\n4. **Application Layer**: User interactions, business metrics, error rates\n\n### Real-Time vs Batch Monitoring\n- **Real-Time**: Inference latency, error rates, resource utilization\n- **Batch**: Model accuracy, data drift analysis, comprehensive performance reports\n\n## Metrics and KPIs for AI Systems\n\n### Technical Metrics\n- **Accuracy/F1 Score**: Model prediction quality\n- **Inference Latency**: Time to generate predictions\n- **Throughput**: Predictions per second\n- **Resource Utilization**: GPU/CPU usage, memory consumption\n- **Error Rate**: Failed predictions or system errors\n\n### Business Metrics\n- **Model ROI**: Business value generated by AI predictions\n- **User Satisfaction**: Feedback on AI-powered features\n- **Conversion Impact**: Effect of AI on business conversions\n- **Cost per Prediction**: Operational costs for AI inference\n\n## Common AI Observability Patterns\n\n### 1. A/B Testing with Models\n```python\ndef ab_test_models(user_id, input_data):\n    model_variant = \"A\" if hash(user_id) % 2 == 0 else \"B\"\n    \n    with sentry_sdk.start_transaction(name=\"ab_test_prediction\") as transaction:\n        transaction.set_tag(\"model_variant\", model_variant)\n        \n        if model_variant == \"A\":\n            prediction = model_a.predict(input_data)\n        else:\n            prediction = model_b.predict(input_data)\n            \n        transaction.set_data(\"prediction\", prediction)\n        return prediction\n```\n\n### 2. Feature Store Monitoring\n```python\ndef monitor_feature_store(feature_name, feature_values):\n    with sentry_sdk.start_transaction(name=\"feature_store_monitoring\"):\n        # Check feature distribution\n        mean_value = np.mean(feature_values)\n        std_value = np.std(feature_values)\n        \n        # Compare with historical baselines\n        if abs(mean_value - historical_mean) > 2 * historical_std:\n            sentry_sdk.capture_message(\n                f\"Feature drift detected in {feature_name}\",\n                level=\"warning\"\n            )\n```\n\n### 3. Model Rollback Strategy\n```python\ndef safe_model_deployment():\n    current_accuracy = monitor_model_performance(new_model, validation_data)\n    baseline_accuracy = get_baseline_accuracy()\n    \n    if current_accuracy < baseline_accuracy - 0.05:  # 5% threshold\n        sentry_sdk.capture_message(\n            \"Model performance regression detected, initiating rollback\",\n            level=\"error\"\n        )\n        rollback_to_previous_model()\n```\n\n## Best Practices for AI Observability\n\n### 1. Establish Baselines Early\n- Collect comprehensive metrics during model development\n- Document expected performance ranges\n- Set up automated alerts for deviations\n\n### 2. Monitor the Full ML Pipeline\n- Data ingestion and preprocessing\n- Feature engineering and selection\n- Model training and validation\n- Inference and serving\n- Post-processing and delivery\n\n### 3. Implement Gradual Rollouts\n- Deploy new models to small traffic percentages\n- Monitor performance before full deployment\n- Maintain rollback capabilities\n\n### 4. Focus on Business Impact\n- Connect technical metrics to business outcomes\n- Monitor user satisfaction and engagement\n- Track revenue impact of AI features\n\n## Tools and Technologies\n\n### Open Source Solutions\n- **MLflow**: Model lifecycle management and tracking\n- **Kubeflow**: Kubernetes-native ML workflows\n- **Prometheus**: Metrics collection and alerting\n- **Grafana**: Visualization and dashboards\n\n### Commercial Platforms\n- **Sentry**: Error tracking and performance monitoring for AI apps\n- **DataDog**: Infrastructure and application monitoring\n- **New Relic**: Full-stack observability with AI insights\n- **Weights & Biases**: Experiment tracking and model monitoring\n\n## Next Steps\n\nIn the following lessons, we'll explore:\n- Setting up comprehensive model monitoring dashboards\n- Implementing automated data quality checks\n- Building alerting systems for AI applications\n- Measuring and optimizing AI system costs\n\nUnderstanding these fundamentals will enable you to build robust, observable AI systems that maintain high performance and reliability in production environments.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.380Z",
    "updatedAt": "2025-06-02T06:52:01.748Z"
  },
  {
    "id": "x4p5y6hqdnwlzegreha55lbp",
    "courseId": "znfssyl27ie0hm5j0d1ss70e",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Model Performance Monitoring\n\n## Understanding Model Performance in Production\n\nModel performance monitoring goes beyond traditional application metrics to include AI-specific indicators that determine whether your models are delivering accurate, reliable predictions in real-world scenarios.\n\n## Core Performance Metrics\n\n### Classification Metrics\n\n#### Accuracy and Beyond\n```python\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport sentry_sdk\n\ndef comprehensive_classification_monitoring(y_true, y_pred, model_version):\n    with sentry_sdk.start_transaction(name=\"classification_monitoring\") as transaction:\n        # Calculate core metrics\n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='weighted')\n        recall = recall_score(y_true, y_pred, average='weighted')\n        f1 = f1_score(y_true, y_pred, average='weighted')\n        \n        # Log metrics with context\n        transaction.set_data(\"model_version\", model_version)\n        transaction.set_data(\"accuracy\", accuracy)\n        transaction.set_data(\"precision\", precision)\n        transaction.set_data(\"recall\", recall)\n        transaction.set_data(\"f1_score\", f1)\n        transaction.set_data(\"sample_size\", len(y_true))\n        \n        # Performance thresholds\n        if accuracy < 0.85:\n            sentry_sdk.capture_message(\n                f\"Model accuracy below threshold: {accuracy:.3f}\",\n                level=\"warning\",\n                extra={\n                    \"model_version\": model_version,\n                    \"metric\": \"accuracy\",\n                    \"value\": accuracy,\n                    \"threshold\": 0.85\n                }\n            )\n        \n        return {\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1_score\": f1\n        }\n```\n\n#### Confusion Matrix Monitoring\n```python\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef monitor_confusion_matrix(y_true, y_pred, class_names):\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Calculate per-class performance\n    class_performance = {}\n    for i, class_name in enumerate(class_names):\n        tp = cm[i, i]\n        fp = cm[:, i].sum() - tp\n        fn = cm[i, :].sum() - tp\n        tn = cm.sum() - tp - fp - fn\n        \n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n        \n        class_performance[class_name] = {\n            \"precision\": precision,\n            \"recall\": recall,\n            \"support\": cm[i, :].sum()\n        }\n        \n        # Alert on poor class performance\n        if precision < 0.7 and cm[i, :].sum() > 10:  # Only alert for classes with sufficient samples\n            sentry_sdk.capture_message(\n                f\"Poor precision for class {class_name}: {precision:.3f}\",\n                level=\"warning\",\n                extra={\n                    \"class_name\": class_name,\n                    \"precision\": precision,\n                    \"recall\": recall,\n                    \"support\": cm[i, :].sum()\n                }\n            )\n    \n    return class_performance\n```\n\n### Regression Metrics\n\n#### Comprehensive Regression Monitoring\n```python\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\ndef monitor_regression_performance(y_true, y_pred, model_version):\n    with sentry_sdk.start_transaction(name=\"regression_monitoring\") as transaction:\n        # Calculate regression metrics\n        mse = mean_squared_error(y_true, y_pred)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(y_true, y_pred)\n        r2 = r2_score(y_true, y_pred)\n        \n        # Calculate residuals statistics\n        residuals = y_true - y_pred\n        residual_std = np.std(residuals)\n        residual_mean = np.mean(residuals)\n        \n        # Log comprehensive metrics\n        transaction.set_data(\"model_version\", model_version)\n        transaction.set_data(\"rmse\", rmse)\n        transaction.set_data(\"mae\", mae)\n        transaction.set_data(\"r2_score\", r2)\n        transaction.set_data(\"residual_std\", residual_std)\n        transaction.set_data(\"residual_mean\", residual_mean)\n        \n        # Performance alerts\n        if r2 < 0.8:  # R² threshold\n            sentry_sdk.capture_message(\n                f\"Low R² score detected: {r2:.3f}\",\n                level=\"warning\",\n                extra={\n                    \"model_version\": model_version,\n                    \"r2_score\": r2,\n                    \"rmse\": rmse,\n                    \"mae\": mae\n                }\n            )\n        \n        # Check for systematic bias\n        if abs(residual_mean) > 0.1 * np.std(y_true):\n            sentry_sdk.capture_message(\n                f\"Systematic bias detected: mean residual = {residual_mean:.3f}\",\n                level=\"warning\",\n                extra={\n                    \"model_version\": model_version,\n                    \"residual_mean\": residual_mean,\n                    \"residual_std\": residual_std\n                }\n            )\n        \n        return {\n            \"rmse\": rmse,\n            \"mae\": mae,\n            \"r2_score\": r2,\n            \"residual_stats\": {\n                \"mean\": residual_mean,\n                \"std\": residual_std\n            }\n        }\n```\n\n## Model Drift Detection\n\n### Data Drift Monitoring\n```python\nfrom scipy import stats\nimport pandas as pd\n\ndef detect_feature_drift(reference_data, current_data, feature_columns):\n    drift_results = {}\n    \n    for feature in feature_columns:\n        if feature in reference_data.columns and feature in current_data.columns:\n            # Kolmogorov-Smirnov test for distribution drift\n            ks_statistic, p_value = stats.ks_2samp(\n                reference_data[feature].dropna(),\n                current_data[feature].dropna()\n            )\n            \n            # Population Stability Index (PSI)\n            psi = calculate_psi(reference_data[feature], current_data[feature])\n            \n            drift_results[feature] = {\n                \"ks_statistic\": ks_statistic,\n                \"p_value\": p_value,\n                \"psi\": psi,\n                \"drift_detected\": p_value < 0.05 or psi > 0.2\n            }\n            \n            # Alert on significant drift\n            if drift_results[feature][\"drift_detected\"]:\n                sentry_sdk.capture_message(\n                    f\"Feature drift detected in {feature}\",\n                    level=\"warning\",\n                    extra={\n                        \"feature\": feature,\n                        \"ks_statistic\": ks_statistic,\n                        \"p_value\": p_value,\n                        \"psi\": psi\n                    }\n                )\n    \n    return drift_results\n\ndef calculate_psi(reference, current, bins=10):\n    \"\"\"Calculate Population Stability Index\"\"\"\n    # Create bins based on reference data\n    _, bin_edges = pd.cut(reference, bins=bins, retbins=True, duplicates='drop')\n    \n    # Calculate distributions\n    ref_dist = pd.cut(reference, bins=bin_edges, include_lowest=True).value_counts().sort_index()\n    cur_dist = pd.cut(current, bins=bin_edges, include_lowest=True).value_counts().sort_index()\n    \n    # Normalize to percentages\n    ref_pct = ref_dist / len(reference)\n    cur_pct = cur_dist / len(current)\n    \n    # Calculate PSI\n    psi = sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct.replace(0, 0.0001)))\n    return psi\n```\n\n### Concept Drift Monitoring\n```python\ndef monitor_concept_drift(model, reference_X, reference_y, current_X, current_y):\n    \"\"\"Monitor for concept drift using model performance comparison\"\"\"\n    \n    with sentry_sdk.start_transaction(name=\"concept_drift_monitoring\") as transaction:\n        # Performance on reference data\n        ref_predictions = model.predict(reference_X)\n        ref_accuracy = accuracy_score(reference_y, ref_predictions)\n        \n        # Performance on current data\n        cur_predictions = model.predict(current_X)\n        cur_accuracy = accuracy_score(current_y, cur_predictions)\n        \n        # Calculate performance degradation\n        performance_drop = ref_accuracy - cur_accuracy\n        performance_drop_pct = (performance_drop / ref_accuracy) * 100\n        \n        transaction.set_data(\"reference_accuracy\", ref_accuracy)\n        transaction.set_data(\"current_accuracy\", cur_accuracy)\n        transaction.set_data(\"performance_drop\", performance_drop)\n        transaction.set_data(\"performance_drop_pct\", performance_drop_pct)\n        \n        # Alert on significant concept drift\n        if performance_drop_pct > 10:  # 10% performance drop threshold\n            sentry_sdk.capture_message(\n                f\"Concept drift detected: {performance_drop_pct:.1f}% performance drop\",\n                level=\"error\",\n                extra={\n                    \"reference_accuracy\": ref_accuracy,\n                    \"current_accuracy\": cur_accuracy,\n                    \"performance_drop_pct\": performance_drop_pct,\n                    \"reference_samples\": len(reference_X),\n                    \"current_samples\": len(current_X)\n                }\n            )\n        \n        return {\n            \"reference_accuracy\": ref_accuracy,\n            \"current_accuracy\": cur_accuracy,\n            \"performance_drop_pct\": performance_drop_pct,\n            \"drift_detected\": performance_drop_pct > 10\n        }\n```\n\n## Real-Time Performance Tracking\n\n### Inference Performance Monitoring\n```python\nimport time\nfrom collections import deque\nfrom threading import Lock\n\nclass InferenceMonitor:\n    def __init__(self, window_size=1000):\n        self.window_size = window_size\n        self.latencies = deque(maxlen=window_size)\n        self.predictions = deque(maxlen=window_size)\n        self.confidence_scores = deque(maxlen=window_size)\n        self.lock = Lock()\n    \n    def record_inference(self, latency, prediction, confidence=None):\n        with self.lock:\n            self.latencies.append(latency)\n            self.predictions.append(prediction)\n            if confidence is not None:\n                self.confidence_scores.append(confidence)\n            \n            # Check for performance issues every 100 inferences\n            if len(self.latencies) % 100 == 0:\n                self._check_performance_alerts()\n    \n    def _check_performance_alerts(self):\n        if len(self.latencies) < 50:  # Need minimum samples\n            return\n        \n        # Calculate performance metrics\n        avg_latency = np.mean(list(self.latencies))\n        p95_latency = np.percentile(list(self.latencies), 95)\n        avg_confidence = np.mean(list(self.confidence_scores)) if self.confidence_scores else None\n        \n        # Latency alerts\n        if avg_latency > 500:  # 500ms threshold\n            sentry_sdk.capture_message(\n                f\"High average inference latency: {avg_latency:.1f}ms\",\n                level=\"warning\",\n                extra={\n                    \"avg_latency_ms\": avg_latency,\n                    \"p95_latency_ms\": p95_latency,\n                    \"sample_count\": len(self.latencies)\n                }\n            )\n        \n        # Confidence alerts\n        if avg_confidence and avg_confidence < 0.7:\n            sentry_sdk.capture_message(\n                f\"Low prediction confidence: {avg_confidence:.3f}\",\n                level=\"warning\",\n                extra={\n                    \"avg_confidence\": avg_confidence,\n                    \"sample_count\": len(self.confidence_scores)\n                }\n            )\n\n# Usage example\nmonitor = InferenceMonitor()\n\ndef monitored_prediction(model, input_data):\n    start_time = time.time()\n    \n    with sentry_sdk.start_transaction(name=\"model_prediction\") as transaction:\n        try:\n            prediction = model.predict(input_data)\n            confidence = getattr(model, 'predict_proba', lambda x: None)(input_data)\n            \n            latency = (time.time() - start_time) * 1000  # Convert to ms\n            \n            # Record metrics\n            monitor.record_inference(\n                latency=latency,\n                prediction=prediction,\n                confidence=confidence.max() if confidence is not None else None\n            )\n            \n            transaction.set_data(\"latency_ms\", latency)\n            transaction.set_data(\"prediction\", prediction)\n            if confidence is not None:\n                transaction.set_data(\"confidence\", confidence.max())\n            \n            return prediction\n            \n        except Exception as e:\n            sentry_sdk.capture_exception(e)\n            raise\n```\n\n## Performance Benchmarking\n\n### A/B Testing Framework\n```python\nclass ModelABTesting:\n    def __init__(self, model_a, model_b, traffic_split=0.5):\n        self.model_a = model_a\n        self.model_b = model_b\n        self.traffic_split = traffic_split\n        self.results = {\"A\": [], \"B\": []}\n    \n    def predict(self, user_id, input_data, ground_truth=None):\n        # Determine model variant\n        variant = \"A\" if hash(str(user_id)) % 100 < (self.traffic_split * 100) else \"B\"\n        model = self.model_a if variant == \"A\" else self.model_b\n        \n        with sentry_sdk.start_transaction(name=\"ab_test_prediction\") as transaction:\n            transaction.set_tag(\"model_variant\", variant)\n            transaction.set_tag(\"user_id\", str(user_id))\n            \n            start_time = time.time()\n            prediction = model.predict(input_data)\n            latency = (time.time() - start_time) * 1000\n            \n            # Record results\n            result = {\n                \"prediction\": prediction,\n                \"latency\": latency,\n                \"timestamp\": time.time()\n            }\n            \n            if ground_truth is not None:\n                result[\"accuracy\"] = (prediction == ground_truth)\n            \n            self.results[variant].append(result)\n            \n            transaction.set_data(\"prediction\", prediction)\n            transaction.set_data(\"latency_ms\", latency)\n            \n            # Periodic performance comparison\n            if len(self.results[\"A\"]) % 1000 == 0 and len(self.results[\"B\"]) % 1000 == 0:\n                self._compare_variants()\n            \n            return prediction\n    \n    def _compare_variants(self):\n        \"\"\"Compare performance between model variants\"\"\"\n        if len(self.results[\"A\"]) < 100 or len(self.results[\"B\"]) < 100:\n            return\n        \n        # Calculate metrics for each variant\n        for variant in [\"A\", \"B\"]:\n            results = self.results[variant]\n            avg_latency = np.mean([r[\"latency\"] for r in results[-1000:]])  # Last 1000 samples\n            \n            if \"accuracy\" in results[0]:  # If ground truth available\n                accuracy = np.mean([r[\"accuracy\"] for r in results[-1000:]])\n                sentry_sdk.set_extra(f\"variant_{variant}_accuracy\", accuracy)\n            \n            sentry_sdk.set_extra(f\"variant_{variant}_latency\", avg_latency)\n        \n        # Log comparison\n        sentry_sdk.capture_message(\n            \"A/B test performance comparison updated\",\n            level=\"info\",\n            extra={\n                \"variant_a_samples\": len(self.results[\"A\"]),\n                \"variant_b_samples\": len(self.results[\"B\"])\n            }\n        )\n```\n\n## Dashboard and Alerting Setup\n\n### Custom Metrics Dashboard\n```python\ndef create_performance_dashboard():\n    \"\"\"Example of key metrics to track in dashboards\"\"\"\n    dashboard_metrics = {\n        \"model_performance\": {\n            \"accuracy\": \"Current model accuracy\",\n            \"precision\": \"Weighted precision score\",\n            \"recall\": \"Weighted recall score\",\n            \"f1_score\": \"F1 score\"\n        },\n        \"operational_metrics\": {\n            \"inference_latency_p50\": \"50th percentile inference time\",\n            \"inference_latency_p95\": \"95th percentile inference time\",\n            \"throughput\": \"Predictions per second\",\n            \"error_rate\": \"Percentage of failed predictions\"\n        },\n        \"data_quality\": {\n            \"missing_values_pct\": \"Percentage of missing values\",\n            \"schema_violations\": \"Number of schema validation errors\",\n            \"feature_drift_score\": \"Average drift score across features\"\n        },\n        \"business_impact\": {\n            \"conversion_rate\": \"Business conversion rate\",\n            \"revenue_impact\": \"Revenue attributed to model predictions\",\n            \"user_satisfaction\": \"User feedback scores\"\n        }\n    }\n    \n    return dashboard_metrics\n```\n\n## Best Practices for Model Performance Monitoring\n\n### 1. Establish Performance Baselines\n- Record comprehensive metrics during model validation\n- Set realistic performance thresholds based on business requirements\n- Document acceptable performance ranges\n\n### 2. Monitor Continuously\n- Implement real-time performance tracking\n- Set up automated alerts for performance degradation\n- Regular batch analysis for deeper insights\n\n### 3. Context-Aware Monitoring\n- Segment performance by user groups, time periods, and data sources\n- Monitor performance across different input distributions\n- Track performance for edge cases and rare events\n\n### 4. Automated Response\n- Implement automatic rollback for severe performance drops\n- Set up escalation procedures for different alert levels\n- Maintain model versioning and deployment history\n\nIn the next lesson, we'll explore data quality monitoring and pipeline observability to ensure your AI systems receive clean, reliable data for optimal performance.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.452Z",
    "updatedAt": "2025-06-02T06:52:01.910Z"
  },
  {
    "id": "fdva6cfa3zsa10uawodxe5cr",
    "courseId": "znfssyl27ie0hm5j0d1ss70e",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Data Quality and Pipeline Monitoring\n\n## Introduction to Data Quality in AI Systems\n\nData quality is the foundation of reliable AI systems. Poor data quality can lead to model drift, biased predictions, and system failures. This lesson covers comprehensive strategies for monitoring data quality and pipeline health in production AI environments.\n\n## Understanding Data Quality Dimensions\n\n### Core Data Quality Metrics\n\n#### Completeness\n```python\nimport pandas as pd\nimport numpy as np\nimport sentry_sdk\nfrom typing import Dict, List, Optional\n\ndef monitor_data_completeness(df: pd.DataFrame, required_columns: List[str]) -> Dict:\n    \"\"\"Monitor data completeness across critical columns\"\"\"\n    \n    with sentry_sdk.start_transaction(name=\"data_completeness_check\") as transaction:\n        completeness_report = {}\n        \n        for column in required_columns:\n            if column in df.columns:\n                total_rows = len(df)\n                missing_count = df[column].isna().sum()\n                completeness_pct = ((total_rows - missing_count) / total_rows) * 100\n                \n                completeness_report[column] = {\n                    \"total_rows\": total_rows,\n                    \"missing_count\": missing_count,\n                    \"completeness_pct\": completeness_pct\n                }\n                \n                # Alert on low completeness\n                if completeness_pct < 95:  # 95% completeness threshold\n                    sentry_sdk.capture_message(\n                        f\"Low data completeness in column {column}: {completeness_pct:.1f}%\",\n                        level=\"warning\",\n                        extra={\n                            \"column\": column,\n                            \"completeness_pct\": completeness_pct,\n                            \"missing_count\": missing_count,\n                            \"total_rows\": total_rows\n                        }\n                    )\n        \n        # Overall completeness score\n        overall_completeness = np.mean([\n            report[\"completeness_pct\"] for report in completeness_report.values()\n        ])\n        \n        transaction.set_data(\"overall_completeness\", overall_completeness)\n        transaction.set_data(\"columns_checked\", len(required_columns))\n        \n        return completeness_report\n```\n\n#### Accuracy and Validity\n```python\ndef monitor_data_validity(df: pd.DataFrame, validation_rules: Dict) -> Dict:\n    \"\"\"Monitor data validity using custom validation rules\"\"\"\n    \n    with sentry_sdk.start_transaction(name=\"data_validity_check\") as transaction:\n        validity_report = {}\n        \n        for column, rules in validation_rules.items():\n            if column not in df.columns:\n                continue\n                \n            column_data = df[column].dropna()\n            valid_count = len(column_data)\n            invalid_count = 0\n            \n            # Range validation\n            if 'min_value' in rules:\n                invalid_count += (column_data < rules['min_value']).sum()\n            if 'max_value' in rules:\n                invalid_count += (column_data > rules['max_value']).sum()\n            \n            # Pattern validation (for strings)\n            if 'pattern' in rules and column_data.dtype == 'object':\n                import re\n                pattern_invalid = ~column_data.str.match(rules['pattern'], na=False)\n                invalid_count += pattern_invalid.sum()\n            \n            # Categorical validation\n            if 'allowed_values' in rules:\n                invalid_count += (~column_data.isin(rules['allowed_values'])).sum()\n            \n            validity_pct = ((valid_count - invalid_count) / valid_count) * 100 if valid_count > 0 else 0\n            \n            validity_report[column] = {\n                \"valid_count\": valid_count - invalid_count,\n                \"invalid_count\": invalid_count,\n                \"validity_pct\": validity_pct\n            }\n            \n            # Alert on low validity\n            if validity_pct < 98:  # 98% validity threshold\n                sentry_sdk.capture_message(\n                    f\"Data validity issues in column {column}: {validity_pct:.1f}%\",\n                    level=\"error\",\n                    extra={\n                        \"column\": column,\n                        \"validity_pct\": validity_pct,\n                        \"invalid_count\": invalid_count,\n                        \"validation_rules\": rules\n                    }\n                )\n        \n        return validity_report\n\n# Example validation rules\nvalidation_rules = {\n    \"age\": {\"min_value\": 0, \"max_value\": 120},\n    \"email\": {\"pattern\": r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}$\"},\n    \"category\": {\"allowed_values\": [\"A\", \"B\", \"C\", \"D\"]},\n    \"score\": {\"min_value\": 0.0, \"max_value\": 1.0}\n}\n```\n\n#### Consistency\n```python\ndef monitor_data_consistency(df: pd.DataFrame, consistency_rules: Dict) -> Dict:\n    \"\"\"Monitor data consistency across related columns\"\"\"\n    \n    with sentry_sdk.start_transaction(name=\"data_consistency_check\") as transaction:\n        consistency_report = {}\n        \n        for rule_name, rule_config in consistency_rules.items():\n            if rule_config['type'] == 'relationship':\n                col1, col2 = rule_config['columns']\n                operator = rule_config['operator']\n                \n                if col1 in df.columns and col2 in df.columns:\n                    valid_data = df[[col1, col2]].dropna()\n                    \n                    if operator == 'greater_than':\n                        violations = (valid_data[col1] <= valid_data[col2]).sum()\n                    elif operator == 'less_than':\n                        violations = (valid_data[col1] >= valid_data[col2]).sum()\n                    elif operator == 'equal':\n                        violations = (valid_data[col1] != valid_data[col2]).sum()\n                    \n                    consistency_pct = ((len(valid_data) - violations) / len(valid_data)) * 100 if len(valid_data) > 0 else 0\n                    \n                    consistency_report[rule_name] = {\n                        \"total_checked\": len(valid_data),\n                        \"violations\": violations,\n                        \"consistency_pct\": consistency_pct\n                    }\n                    \n                    # Alert on consistency violations\n                    if consistency_pct < 99:  # 99% consistency threshold\n                        sentry_sdk.capture_message(\n                            f\"Data consistency violation in rule {rule_name}: {consistency_pct:.1f}%\",\n                            level=\"warning\",\n                            extra={\n                                \"rule_name\": rule_name,\n                                \"consistency_pct\": consistency_pct,\n                                \"violations\": violations,\n                                \"rule_config\": rule_config\n                            }\n                        )\n        \n        return consistency_report\n\n# Example consistency rules\nconsistency_rules = {\n    \"start_end_date\": {\n        \"type\": \"relationship\",\n        \"columns\": [\"start_date\", \"end_date\"],\n        \"operator\": \"less_than\"\n    },\n    \"min_max_values\": {\n        \"type\": \"relationship\", \n        \"columns\": [\"min_value\", \"max_value\"],\n        \"operator\": \"less_than\"\n    }\n}\n```\n\n## Pipeline Health Monitoring\n\n### Data Pipeline Stages\n```python\nfrom datetime import datetime, timedelta\nimport time\n\nclass PipelineStageMonitor:\n    def __init__(self, stage_name: str):\n        self.stage_name = stage_name\n        self.start_time = None\n        self.transaction = None\n    \n    def __enter__(self):\n        self.start_time = time.time()\n        self.transaction = sentry_sdk.start_transaction(\n            name=f\"pipeline_stage_{self.stage_name}\"\n        )\n        self.transaction.set_tag(\"stage_name\", self.stage_name)\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        duration = time.time() - self.start_time\n        \n        if exc_type is None:\n            # Success\n            self.transaction.set_data(\"duration_seconds\", duration)\n            self.transaction.set_data(\"status\", \"success\")\n            \n            # Check for performance issues\n            if duration > 300:  # 5 minutes threshold\n                sentry_sdk.capture_message(\n                    f\"Slow pipeline stage: {self.stage_name} took {duration:.1f}s\",\n                    level=\"warning\",\n                    extra={\n                        \"stage_name\": self.stage_name,\n                        \"duration_seconds\": duration\n                    }\n                )\n        else:\n            # Failure\n            self.transaction.set_data(\"status\", \"error\")\n            sentry_sdk.capture_exception(exc_val)\n        \n        self.transaction.finish()\n\n# Usage example\ndef data_ingestion_pipeline():\n    with PipelineStageMonitor(\"data_extraction\"):\n        raw_data = extract_data_from_source()\n    \n    with PipelineStageMonitor(\"data_transformation\"):\n        cleaned_data = transform_data(raw_data)\n    \n    with PipelineStageMonitor(\"data_validation\"):\n        validated_data = validate_data(cleaned_data)\n    \n    with PipelineStageMonitor(\"data_loading\"):\n        load_data_to_destination(validated_data)\n```\n\n### Real-time Data Quality Monitoring\n```python\nclass RealTimeDataQualityMonitor:\n    def __init__(self, alert_thresholds: Dict):\n        self.alert_thresholds = alert_thresholds\n        self.recent_metrics = {}\n    \n    def process_batch(self, batch_data: pd.DataFrame, batch_id: str):\n        \"\"\"Process a data batch and monitor quality metrics\"\"\"\n        \n        with sentry_sdk.start_transaction(name=\"batch_quality_monitoring\") as transaction:\n            transaction.set_tag(\"batch_id\", batch_id)\n            transaction.set_data(\"batch_size\", len(batch_data))\n            \n            # Calculate quality metrics\n            quality_metrics = self._calculate_quality_metrics(batch_data)\n            \n            # Store metrics for trend analysis\n            self.recent_metrics[batch_id] = {\n                \"timestamp\": datetime.now(),\n                \"metrics\": quality_metrics\n            }\n            \n            # Check for alerts\n            self._check_quality_alerts(quality_metrics, batch_id)\n            \n            # Log metrics\n            for metric_name, value in quality_metrics.items():\n                transaction.set_data(metric_name, value)\n            \n            return quality_metrics\n    \n    def _calculate_quality_metrics(self, df: pd.DataFrame) -> Dict:\n        \"\"\"Calculate comprehensive quality metrics for a batch\"\"\"\n        metrics = {}\n        \n        # Completeness\n        metrics['completeness_pct'] = (1 - df.isna().sum().sum() / (len(df) * len(df.columns))) * 100\n        \n        # Uniqueness (for ID columns)\n        if 'id' in df.columns:\n            metrics['uniqueness_pct'] = (df['id'].nunique() / len(df)) * 100\n        \n        # Consistency (data type adherence)\n        numeric_columns = df.select_dtypes(include=[np.number]).columns\n        if len(numeric_columns) > 0:\n            metrics['numeric_consistency_pct'] = 100  # Assume consistent if selected correctly\n        \n        # Timeliness (if timestamp column exists)\n        if 'timestamp' in df.columns:\n            latest_timestamp = pd.to_datetime(df['timestamp']).max()\n            time_lag = (datetime.now() - latest_timestamp).total_seconds() / 3600  # hours\n            metrics['data_freshness_hours'] = time_lag\n        \n        # Volume\n        metrics['record_count'] = len(df)\n        \n        return metrics\n    \n    def _check_quality_alerts(self, metrics: Dict, batch_id: str):\n        \"\"\"Check metrics against thresholds and send alerts\"\"\"\n        \n        for metric_name, value in metrics.items():\n            if metric_name in self.alert_thresholds:\n                threshold = self.alert_thresholds[metric_name]\n                \n                if metric_name.endswith('_pct') and value < threshold['min']:\n                    sentry_sdk.capture_message(\n                        f\"Data quality alert: {metric_name} below threshold\",\n                        level=\"error\",\n                        extra={\n                            \"metric_name\": metric_name,\n                            \"current_value\": value,\n                            \"threshold\": threshold['min'],\n                            \"batch_id\": batch_id\n                        }\n                    )\n                elif metric_name == 'data_freshness_hours' and value > threshold['max']:\n                    sentry_sdk.capture_message(\n                        f\"Data freshness alert: data is {value:.1f} hours old\",\n                        level=\"warning\",\n                        extra={\n                            \"metric_name\": metric_name,\n                            \"current_value\": value,\n                            \"threshold\": threshold['max'],\n                            \"batch_id\": batch_id\n                        }\n                    )\n\n# Configuration example\nalert_thresholds = {\n    'completeness_pct': {'min': 95.0},\n    'uniqueness_pct': {'min': 99.0},\n    'data_freshness_hours': {'max': 2.0}\n}\n\nmonitor = RealTimeDataQualityMonitor(alert_thresholds)\n```\n\n## Feature Store Monitoring\n\n### Feature Drift Detection\n```python\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\nclass FeatureDriftMonitor:\n    def __init__(self, reference_data: pd.DataFrame, feature_columns: List[str]):\n        self.reference_data = reference_data[feature_columns]\n        self.feature_columns = feature_columns\n        self.scaler = StandardScaler()\n        self.reference_stats = self._calculate_reference_stats()\n    \n    def _calculate_reference_stats(self) -> Dict:\n        \"\"\"Calculate reference statistics for drift detection\"\"\"\n        stats = {}\n        for column in self.feature_columns:\n            if column in self.reference_data.columns:\n                data = self.reference_data[column].dropna()\n                stats[column] = {\n                    'mean': data.mean(),\n                    'std': data.std(),\n                    'min': data.min(),\n                    'max': data.max(),\n                    'q25': data.quantile(0.25),\n                    'q50': data.quantile(0.50),\n                    'q75': data.quantile(0.75)\n                }\n        return stats\n    \n    def detect_drift(self, current_data: pd.DataFrame) -> Dict:\n        \"\"\"Detect feature drift between reference and current data\"\"\"\n        \n        with sentry_sdk.start_transaction(name=\"feature_drift_detection\") as transaction:\n            drift_results = {}\n            \n            for column in self.feature_columns:\n                if column not in current_data.columns:\n                    continue\n                \n                reference_values = self.reference_data[column].dropna()\n                current_values = current_data[column].dropna()\n                \n                if len(current_values) < 100:  # Need sufficient samples\n                    continue\n                \n                # Statistical tests\n                drift_metrics = self._calculate_drift_metrics(\n                    reference_values, current_values, column\n                )\n                \n                drift_results[column] = drift_metrics\n                \n                # Alert on significant drift\n                if drift_metrics['drift_detected']:\n                    sentry_sdk.capture_message(\n                        f\"Feature drift detected in {column}\",\n                        level=\"warning\",\n                        extra={\n                            \"feature\": column,\n                            \"drift_score\": drift_metrics['drift_score'],\n                            \"ks_pvalue\": drift_metrics['ks_pvalue'],\n                            \"mean_shift\": drift_metrics['mean_shift'],\n                            \"std_shift\": drift_metrics['std_shift']\n                        }\n                    )\n            \n            # Overall drift score\n            overall_drift_score = np.mean([\n                result['drift_score'] for result in drift_results.values()\n            ])\n            \n            transaction.set_data(\"overall_drift_score\", overall_drift_score)\n            transaction.set_data(\"features_checked\", len(drift_results))\n            \n            return drift_results\n    \n    def _calculate_drift_metrics(self, reference: pd.Series, current: pd.Series, column: str) -> Dict:\n        \"\"\"Calculate comprehensive drift metrics for a feature\"\"\"\n        \n        # Kolmogorov-Smirnov test\n        ks_statistic, ks_pvalue = stats.ks_2samp(reference, current)\n        \n        # Population Stability Index (PSI)\n        psi = self._calculate_psi(reference, current)\n        \n        # Statistical differences\n        ref_stats = self.reference_stats[column]\n        curr_mean = current.mean()\n        curr_std = current.std()\n        \n        mean_shift = abs(curr_mean - ref_stats['mean']) / ref_stats['std']\n        std_shift = abs(curr_std - ref_stats['std']) / ref_stats['std']\n        \n        # Combine metrics into drift score\n        drift_score = (ks_statistic + psi + min(mean_shift, 3) + min(std_shift, 3)) / 4\n        \n        # Determine if drift is significant\n        drift_detected = (\n            ks_pvalue < 0.05 or  # Significant distribution change\n            psi > 0.2 or         # High PSI\n            mean_shift > 2 or    # Large mean shift (2 standard deviations)\n            std_shift > 0.5      # Large variance change\n        )\n        \n        return {\n            'drift_score': drift_score,\n            'ks_statistic': ks_statistic,\n            'ks_pvalue': ks_pvalue,\n            'psi': psi,\n            'mean_shift': mean_shift,\n            'std_shift': std_shift,\n            'drift_detected': drift_detected,\n            'current_mean': curr_mean,\n            'current_std': curr_std,\n            'reference_mean': ref_stats['mean'],\n            'reference_std': ref_stats['std']\n        }\n    \n    def _calculate_psi(self, reference: pd.Series, current: pd.Series, bins=10) -> float:\n        \"\"\"Calculate Population Stability Index\"\"\"\n        try:\n            # Create bins based on reference data\n            _, bin_edges = pd.cut(reference, bins=bins, retbins=True, duplicates='drop')\n            \n            # Calculate distributions\n            ref_dist = pd.cut(reference, bins=bin_edges, include_lowest=True).value_counts().sort_index()\n            cur_dist = pd.cut(current, bins=bin_edges, include_lowest=True).value_counts().sort_index()\n            \n            # Normalize to percentages and avoid division by zero\n            ref_pct = ref_dist / len(reference)\n            cur_pct = cur_dist / len(current)\n            \n            # Replace zeros with small value to avoid log(0)\n            ref_pct = ref_pct.replace(0, 0.0001)\n            cur_pct = cur_pct.replace(0, 0.0001)\n            \n            # Calculate PSI\n            psi = sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct))\n            return float(psi)\n        \n        except Exception as e:\n            sentry_sdk.capture_exception(e)\n            return 0.0  # Return 0 if calculation fails\n```\n\n## Data Lineage and Provenance Tracking\n\n### Data Lineage Monitoring\n```python\nclass DataLineageTracker:\n    def __init__(self):\n        self.lineage_graph = {}\n    \n    def track_transformation(self, \n                           source_dataset: str, \n                           target_dataset: str, \n                           transformation_type: str,\n                           metadata: Dict = None):\n        \"\"\"Track data transformations for lineage\"\"\"\n        \n        lineage_entry = {\n            \"source\": source_dataset,\n            \"target\": target_dataset,\n            \"transformation\": transformation_type,\n            \"timestamp\": datetime.now().isoformat(),\n            \"metadata\": metadata or {}\n        }\n        \n        # Log to Sentry for audit trail\n        sentry_sdk.capture_message(\n            f\"Data transformation: {source_dataset} → {target_dataset}\",\n            level=\"info\",\n            extra=lineage_entry\n        )\n        \n        # Store in lineage graph\n        if target_dataset not in self.lineage_graph:\n            self.lineage_graph[target_dataset] = []\n        \n        self.lineage_graph[target_dataset].append(lineage_entry)\n    \n    def get_data_lineage(self, dataset: str) -> List[Dict]:\n        \"\"\"Get complete lineage for a dataset\"\"\"\n        return self.lineage_graph.get(dataset, [])\n    \n    def validate_data_freshness(self, dataset: str, max_age_hours: int = 24):\n        \"\"\"Validate that data is fresh enough for use\"\"\"\n        lineage = self.get_data_lineage(dataset)\n        \n        if not lineage:\n            sentry_sdk.capture_message(\n                f\"No lineage found for dataset {dataset}\",\n                level=\"warning\",\n                extra={\"dataset\": dataset}\n            )\n            return False\n        \n        latest_update = max([\n            datetime.fromisoformat(entry[\"timestamp\"]) \n            for entry in lineage\n        ])\n        \n        age_hours = (datetime.now() - latest_update).total_seconds() / 3600\n        \n        if age_hours > max_age_hours:\n            sentry_sdk.capture_message(\n                f\"Stale data detected: {dataset} is {age_hours:.1f} hours old\",\n                level=\"error\",\n                extra={\n                    \"dataset\": dataset,\n                    \"age_hours\": age_hours,\n                    \"max_age_hours\": max_age_hours,\n                    \"last_update\": latest_update.isoformat()\n                }\n            )\n            return False\n        \n        return True\n\n# Usage example\nlineage_tracker = DataLineageTracker()\n\ndef process_user_data():\n    # Track data movement through pipeline\n    lineage_tracker.track_transformation(\n        source_dataset=\"raw_user_events\",\n        target_dataset=\"cleaned_user_events\", \n        transformation_type=\"data_cleaning\",\n        metadata={\"records_processed\": 10000, \"cleaning_rules\": [\"remove_duplicates\", \"validate_timestamps\"]}\n    )\n    \n    lineage_tracker.track_transformation(\n        source_dataset=\"cleaned_user_events\",\n        target_dataset=\"user_features\",\n        transformation_type=\"feature_engineering\",\n        metadata={\"features_created\": [\"session_duration\", \"page_views\", \"bounce_rate\"]}\n    )\n```\n\n## Best Practices for Data Quality Monitoring\n\n### 1. Establish Data Quality SLAs\n- Define acceptable ranges for completeness, accuracy, and freshness\n- Set up automated monitoring for critical data quality metrics\n- Implement escalation procedures for data quality violations\n\n### 2. Proactive Monitoring\n- Monitor data quality at ingestion, transformation, and consumption points\n- Implement real-time alerts for critical data quality issues\n- Regular batch analysis for trend detection\n\n### 3. Data Validation Gates\n- Implement validation checkpoints in data pipelines\n- Fail fast on critical data quality violations\n- Maintain data quality history for trend analysis\n\n### 4. Collaborative Data Quality\n- Involve data producers in quality monitoring\n- Provide feedback loops for data quality improvements\n- Share data quality metrics across teams\n\n### 5. Continuous Improvement\n- Regular review of data quality thresholds\n- Update validation rules based on evolving data patterns\n- Invest in data quality tooling and automation\n\nThis comprehensive approach to data quality and pipeline monitoring ensures that your AI systems receive reliable, high-quality data, enabling consistent model performance and reliable predictions in production environments.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:17.570Z",
    "updatedAt": "2025-06-02T06:52:01.992Z"
  },
  {
    "id": "t8ynu2zfimmsh55kolsxa1d8",
    "courseId": "xzf8dsrwmu8jhzvj12perj95",
    "title": "Introduction to Understanding and implementing Session Replay",
    "slug": "introduction-to-understanding-and-implementing-session-replay",
    "description": "Get started with Understanding and implementing Session Replay",
    "type": "text",
    "content": "# What is Session Replay?\n\n## Introduction to Session Replay Technology\n\nSession Replay is a powerful observability tool that records and recreates user interactions with web applications. Unlike traditional analytics that only provide statistical data, session replay captures the actual user experience, allowing developers to see exactly what users see and do on their websites.\n\n## How Session Replay Works\n\n### Core Recording Mechanism\nSession replay works by capturing DOM mutations, user interactions, and browser events in real-time, then reconstructing them for later playback.\n\n```javascript\n// Basic session replay initialization with Sentry\nimport * as Sentry from \"@sentry/browser\";\n\nSentry.init({\n  dsn: \"YOUR_SENTRY_DSN\",\n  integrations: [\n    new Sentry.Replay({\n      // Capture 10% of normal sessions\n      sessionSampleRate: 0.1,\n      // Capture 100% of sessions with errors\n      errorSampleRate: 1.0,\n      // Mask sensitive data\n      maskAllText: false,\n      blockAllMedia: true,\n    }),\n  ],\n});\n```\n\n### What Gets Recorded\n- **DOM Structure**: Initial page structure and all subsequent changes\n- **User Interactions**: Clicks, scrolls, form inputs, hovers\n- **Network Activity**: API calls, resource loading, errors\n- **Console Logs**: JavaScript errors and custom log messages\n- **Page Navigation**: Route changes and page transitions\n\n### Privacy-First Recording\n```javascript\n// Advanced privacy configuration\nconst replayIntegration = new Sentry.Replay({\n  // Mask sensitive form inputs\n  maskAllInputs: true,\n  \n  // Block specific elements\n  block: ['.sensitive-data', '#credit-card-form'],\n  \n  // Mask text content\n  mask: ['.user-name', '.email-address'],\n  \n  // Custom privacy rules\n  beforeAddRecordingEvent: (event) => {\n    // Custom logic to filter sensitive events\n    if (event.type === 'input' && event.target?.name === 'password') {\n      return null; // Don't record password inputs\n    }\n    return event;\n  }\n});\n```\n\n## Benefits of Session Replay\n\n### 1. Enhanced Debugging Capabilities\nSession replay transforms debugging from guesswork into precise problem identification:\n\n```javascript\n// Example: Debugging with replay context\nfunction handlePaymentError(error) {\n  Sentry.captureException(error, {\n    tags: {\n      section: 'payment',\n      user_action: 'checkout'\n    },\n    extra: {\n      payment_method: 'credit_card',\n      cart_value: 150.00\n    }\n  });\n  \n  // The associated replay will show exactly what the user\n  // was doing when this error occurred\n}\n```\n\n### 2. User Experience Optimization\n- **Identify UX Pain Points**: See where users struggle or get confused\n- **Conversion Funnel Analysis**: Watch actual user behavior through conversion flows\n- **Performance Issues**: Spot slow-loading elements affecting user experience\n\n### 3. Quality Assurance\n- **Bug Reproduction**: Reproduce issues exactly as users experienced them\n- **Edge Case Discovery**: Find unexpected user behaviors and edge cases\n- **Feature Validation**: Verify that new features work as intended in real usage\n\n## Types of Session Replay\n\n### Full Session Recording\nRecords complete user sessions from start to finish:\n\n```javascript\n// Configuration for full session recording\nconst fullSessionReplay = new Sentry.Replay({\n  sessionSampleRate: 0.1, // Record 10% of all sessions\n  maxReplayDuration: 60 * 60 * 1000, // 1 hour max\n  minReplayDuration: 5 * 1000, // 5 seconds minimum\n});\n```\n\n### Error-Triggered Recording\nOnly records sessions when errors occur:\n\n```javascript\n// Error-only recording for better performance\nconst errorOnlyReplay = new Sentry.Replay({\n  sessionSampleRate: 0, // Don't record normal sessions\n  errorSampleRate: 1.0, // Record 100% of error sessions\n  onErrorSampleRate: 1.0 // Also record when errors occur\n});\n```\n\n### Conditional Recording\nRecord based on specific conditions:\n\n```javascript\n// Custom conditional recording\nconst conditionalReplay = new Sentry.Replay({\n  sessionSampleRate: 0,\n  shouldCreateReplaySession: () => {\n    // Only record for premium users\n    return user.isPremium && Math.random() < 0.5;\n  }\n});\n```\n\n## Session Replay Architecture\n\n### Client-Side Components\n1. **Event Capture**: Records DOM mutations and user interactions\n2. **Data Compression**: Reduces payload size for efficient transmission\n3. **Privacy Filtering**: Applies masking and blocking rules\n4. **Buffering**: Manages memory usage and network transmission\n\n### Server-Side Processing\n1. **Event Storage**: Stores compressed replay data\n2. **Indexing**: Creates searchable metadata\n3. **Replay Generation**: Reconstructs sessions for playback\n4. **Analytics**: Generates insights from replay data\n\n## Implementation Considerations\n\n### Performance Impact\nSession replay is designed to have minimal performance impact:\n\n```javascript\n// Performance monitoring during replay\nconst performanceObserver = new PerformanceObserver((list) => {\n  for (const entry of list.getEntries()) {\n    if (entry.duration > 100) { // Log slow operations\n      console.warn('Slow operation detected:', entry.name, entry.duration);\n    }\n  }\n});\n\nperformanceObserver.observe({ entryTypes: ['measure', 'navigation'] });\n\n// Replay with performance monitoring\nconst performantReplay = new Sentry.Replay({\n  sessionSampleRate: 0.1,\n  // Use compression to reduce bandwidth\n  useCompression: true,\n  // Limit network usage\n  networkDetailAllowed: false,\n  // Optimize for performance\n  collectFonts: false\n});\n```\n\n### Storage and Bandwidth\n- **Compression**: Modern replay tools use advanced compression algorithms\n- **Selective Recording**: Record only important interactions\n- **Sampling**: Use appropriate sampling rates to balance insights with costs\n\n### Browser Compatibility\n```javascript\n// Check browser support before initializing\nfunction initializeReplay() {\n  if (!window.MutationObserver || !window.JSON) {\n    console.warn('Session replay not supported in this browser');\n    return;\n  }\n  \n  const replay = new Sentry.Replay({\n    sessionSampleRate: 0.1,\n    errorSampleRate: 1.0\n  });\n  \n  return replay;\n}\n```\n\n## Common Use Cases\n\n### 1. Customer Support\n```javascript\n// Link replay to support tickets\nfunction createSupportTicket(issueDescription) {\n  const replayId = Sentry.getCurrentHub().getScope()?.getReplay()?.getReplayId();\n  \n  return submitTicket({\n    description: issueDescription,\n    replayId: replayId,\n    timestamp: Date.now(),\n    userAgent: navigator.userAgent\n  });\n}\n```\n\n### 2. Product Analytics\n```javascript\n// Track feature usage with replay context\nfunction trackFeatureUsage(featureName, success) {\n  Sentry.addBreadcrumb({\n    message: `Feature used: ${featureName}`,\n    category: 'user-action',\n    data: {\n      feature: featureName,\n      success: success,\n      timestamp: Date.now()\n    }\n  });\n  \n  if (!success) {\n    Sentry.captureMessage(`Feature failure: ${featureName}`, 'warning');\n  }\n}\n```\n\n### 3. A/B Testing\n```javascript\n// Replay-enhanced A/B testing\nfunction initializeABTest() {\n  const variant = getABTestVariant();\n  \n  Sentry.setTag('ab_test_variant', variant);\n  \n  // Apply variant-specific changes\n  if (variant === 'new_checkout') {\n    enableNewCheckoutFlow();\n  }\n  \n  // Track conversion with replay context\n  trackConversion('checkout_completed', {\n    variant: variant,\n    replayId: Sentry.getCurrentHub().getScope()?.getReplay()?.getReplayId()\n  });\n}\n```\n\n## Privacy and Compliance\n\n### GDPR Compliance\n```javascript\n// GDPR-compliant replay setup\nconst gdprCompliantReplay = new Sentry.Replay({\n  // Only record with explicit consent\n  sessionSampleRate: userHasConsented() ? 0.1 : 0,\n  \n  // Mask all personal data\n  maskAllText: true,\n  maskAllInputs: true,\n  \n  // Block sensitive areas\n  block: [\n    '.gdpr-sensitive',\n    '[data-sensitive]',\n    '.personal-info'\n  ],\n  \n  // Custom privacy handler\n  beforeAddRecordingEvent: (event) => {\n    // Additional privacy checks\n    if (containsPersonalData(event)) {\n      return maskPersonalData(event);\n    }\n    return event;\n  }\n});\n```\n\n### Data Retention\n```javascript\n// Configure data retention policies\nconst replayWithRetention = new Sentry.Replay({\n  sessionSampleRate: 0.1,\n  \n  // Custom metadata for retention\n  beforeSend: (event) => {\n    event.extra = {\n      ...event.extra,\n      retention_policy: 'standard_30_days',\n      data_classification: 'internal',\n      created_at: new Date().toISOString()\n    };\n    return event;\n  }\n});\n```\n\n## Integration with Development Workflow\n\n### CI/CD Integration\n```javascript\n// Environment-specific replay configuration\nconst getReplayConfig = () => {\n  const environment = process.env.NODE_ENV;\n  \n  if (environment === 'production') {\n    return {\n      sessionSampleRate: 0.05,\n      errorSampleRate: 1.0,\n      maskAllText: true\n    };\n  } else if (environment === 'staging') {\n    return {\n      sessionSampleRate: 0.2,\n      errorSampleRate: 1.0,\n      maskAllText: false\n    };\n  } else {\n    return {\n      sessionSampleRate: 1.0, // Record all in development\n      errorSampleRate: 1.0,\n      maskAllText: false\n    };\n  }\n};\n\nSentry.init({\n  dsn: process.env.SENTRY_DSN,\n  environment: process.env.NODE_ENV,\n  integrations: [\n    new Sentry.Replay(getReplayConfig())\n  ]\n});\n```\n\n### Testing with Replay\n```javascript\n// E2E testing with replay validation\ndescribe('Checkout Flow', () => {\n  beforeEach(() => {\n    // Enable replay for test sessions\n    cy.window().then((win) => {\n      win.Sentry?.init({\n        dsn: 'test-dsn',\n        integrations: [\n          new win.Sentry.Replay({\n            sessionSampleRate: 1.0\n          })\n        ]\n      });\n    });\n  });\n  \n  it('should complete purchase successfully', () => {\n    cy.visit('/checkout');\n    cy.get('[data-testid=\"purchase-button\"]').click();\n    \n    // Verify replay captured the interaction\n    cy.window().then((win) => {\n      const replayId = win.Sentry?.getCurrentHub()\n        ?.getScope()?.getReplay()?.getReplayId();\n      expect(replayId).to.exist;\n    });\n  });\n});\n```\n\n## Best Practices\n\n### 1. Sampling Strategy\n- Start with low sampling rates (1-5%) and adjust based on value\n- Use higher rates for critical user journeys\n- Implement dynamic sampling based on user segments\n\n### 2. Privacy by Design\n- Default to maximum privacy settings\n- Implement granular privacy controls\n- Regular privacy audits and compliance checks\n\n### 3. Performance Optimization\n- Monitor replay overhead in production\n- Use compression and efficient sampling\n- Implement circuit breakers for high-traffic scenarios\n\n### 4. Team Training\n- Train developers on replay analysis techniques\n- Establish workflows for replay-driven debugging\n- Create playbooks for common replay scenarios\n\nSession replay is a transformative technology that bridges the gap between user experience and technical implementation, providing unprecedented visibility into how users actually interact with your applications.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.666Z",
    "updatedAt": "2025-06-02T06:59:22.073Z"
  },
  {
    "id": "fyqdhzwobo4px9y3224s5zxa",
    "courseId": "xzf8dsrwmu8jhzvj12perj95",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Setting Up Session Replay\n\n## Planning Your Session Replay Implementation\n\nBefore implementing session replay, it's crucial to establish a comprehensive strategy that addresses technical requirements, privacy considerations, and business objectives.\n\n### Implementation Strategy\n\n#### 1. Define Recording Objectives\n```javascript\n// Example configuration based on different objectives\nconst REPLAY_OBJECTIVES = {\n  DEBUGGING: {\n    sessionSampleRate: 0.05,\n    errorSampleRate: 1.0,\n    minReplayDuration: 10000, // 10 seconds\n    networkDetailAllowed: true\n  },\n  \n  UX_RESEARCH: {\n    sessionSampleRate: 0.2,\n    errorSampleRate: 1.0,\n    recordCanvas: true,\n    collectFonts: true\n  },\n  \n  CUSTOMER_SUPPORT: {\n    sessionSampleRate: 0.1,\n    errorSampleRate: 1.0,\n    maskAllInputs: false, // With user consent\n    maxReplayDuration: 3600000 // 1 hour\n  }\n};\n\nfunction getReplayConfig(objective) {\n  return REPLAY_OBJECTIVES[objective] || REPLAY_OBJECTIVES.DEBUGGING;\n}\n```\n\n#### 2. Privacy Assessment\n```javascript\n// Privacy configuration matrix\nconst PRIVACY_LEVELS = {\n  STRICT: {\n    maskAllText: true,\n    maskAllInputs: true,\n    blockAllMedia: true,\n    block: ['.sensitive', '[data-private]', '.pii'],\n    beforeAddRecordingEvent: (event) => {\n      // Aggressive filtering\n      if (event.type === 'input' || event.type === 'change') {\n        return null;\n      }\n      return event;\n    }\n  },\n  \n  MODERATE: {\n    maskAllText: false,\n    maskAllInputs: true,\n    blockAllMedia: false,\n    mask: ['.user-data', '.financial-info'],\n    block: ['.credit-card', '.ssn']\n  },\n  \n  MINIMAL: {\n    maskAllText: false,\n    maskAllInputs: false,\n    blockAllMedia: false,\n    mask: ['.password', '.credit-card-number']\n  }\n};\n```\n\n## Technical Implementation\n\n### Core Setup with Sentry\n\n#### Basic Integration\n```javascript\nimport * as Sentry from \"@sentry/browser\";\n\n// Environment-aware configuration\nconst isDevelopment = process.env.NODE_ENV === 'development';\nconst isProduction = process.env.NODE_ENV === 'production';\n\nSentry.init({\n  dsn: process.env.REACT_APP_SENTRY_DSN,\n  environment: process.env.NODE_ENV,\n  \n  integrations: [\n    new Sentry.Replay({\n      // Sampling rates based on environment\n      sessionSampleRate: isDevelopment ? 1.0 : 0.1,\n      errorSampleRate: 1.0,\n      \n      // Privacy settings\n      maskAllText: isProduction,\n      maskAllInputs: isProduction,\n      \n      // Performance settings\n      useCompression: true,\n      networkDetailAllowed: !isProduction,\n      \n      // Custom configuration\n      beforeAddRecordingEvent: (event, hint) => {\n        return filterSensitiveEvents(event, hint);\n      }\n    })\n  ],\n  \n  // Other Sentry configuration\n  tracesSampleRate: isDevelopment ? 1.0 : 0.1,\n  debug: isDevelopment\n});\n\nfunction filterSensitiveEvents(event, hint) {\n  // Custom filtering logic\n  if (event.type === 'input' && event.target?.type === 'password') {\n    return null; // Don't record password inputs\n  }\n  \n  if (event.type === 'click' && event.target?.dataset?.sensitive) {\n    return null; // Don't record clicks on sensitive elements\n  }\n  \n  return event;\n}\n```\n\n#### Advanced Configuration\n```javascript\n// Advanced replay setup with custom options\nclass SessionReplayManager {\n  constructor(config = {}) {\n    this.config = {\n      maxReplayDuration: 60 * 60 * 1000, // 1 hour\n      minReplayDuration: 5 * 1000, // 5 seconds\n      maxReplaySize: 50 * 1024 * 1024, // 50MB\n      ...config\n    };\n    \n    this.replayInstance = null;\n    this.isRecording = false;\n  }\n  \n  async initialize() {\n    try {\n      // Check browser compatibility\n      if (!this.isBrowserSupported()) {\n        console.warn('Session replay not supported in this browser');\n        return false;\n      }\n      \n      // Initialize Sentry with replay\n      Sentry.init({\n        dsn: process.env.REACT_APP_SENTRY_DSN,\n        integrations: [\n          new Sentry.Replay({\n            sessionSampleRate: this.config.sessionSampleRate,\n            errorSampleRate: this.config.errorSampleRate,\n            maxReplayDuration: this.config.maxReplayDuration,\n            minReplayDuration: this.config.minReplayDuration,\n            \n            // Custom event filtering\n            beforeAddRecordingEvent: this.filterEvents.bind(this),\n            \n            // Privacy controls\n            ...this.getPrivacyConfig(),\n            \n            // Performance optimizations\n            ...this.getPerformanceConfig()\n          })\n        ]\n      });\n      \n      this.isRecording = true;\n      this.setupEventListeners();\n      \n      return true;\n    } catch (error) {\n      console.error('Failed to initialize session replay:', error);\n      return false;\n    }\n  }\n  \n  isBrowserSupported() {\n    return !!(\n      window.MutationObserver &&\n      window.JSON &&\n      window.localStorage &&\n      'addEventListener' in window\n    );\n  }\n  \n  getPrivacyConfig() {\n    const userConsent = this.getUserConsent();\n    \n    if (!userConsent.functional) {\n      return { sessionSampleRate: 0 }; // No recording without consent\n    }\n    \n    return {\n      maskAllText: !userConsent.analytics,\n      maskAllInputs: true,\n      blockAllMedia: !userConsent.analytics,\n      mask: [\n        '.sensitive-data',\n        '[data-private]',\n        '.user-email',\n        '.phone-number'\n      ],\n      block: [\n        '.credit-card-form',\n        '.password-field',\n        '.ssn-input',\n        '.security-question'\n      ]\n    };\n  }\n  \n  getPerformanceConfig() {\n    return {\n      useCompression: true,\n      collectFonts: false, // Reduce payload size\n      recordCanvas: false, // Disable canvas recording for performance\n      networkDetailAllowed: false, // Reduce data collection\n      \n      // Custom sampling based on device performance\n      sessionSampleRate: this.getAdaptiveSampleRate()\n    };\n  }\n  \n  getAdaptiveSampleRate() {\n    try {\n      // Adjust sampling based on device capabilities\n      const memory = navigator.deviceMemory || 4; // GB\n      const cores = navigator.hardwareConcurrency || 4;\n      const connection = navigator.connection?.effectiveType || '4g';\n      \n      let sampleRate = 0.1; // Default 10%\n      \n      // Reduce sampling on low-end devices\n      if (memory < 4 || cores < 4) {\n        sampleRate *= 0.5;\n      }\n      \n      // Reduce sampling on slow connections\n      if (connection === 'slow-2g' || connection === '2g') {\n        sampleRate *= 0.3;\n      } else if (connection === '3g') {\n        sampleRate *= 0.7;\n      }\n      \n      return Math.max(sampleRate, 0.01); // Minimum 1%\n    } catch (error) {\n      return 0.1; // Default fallback\n    }\n  }\n  \n  filterEvents(event, hint) {\n    // Performance filtering\n    if (this.shouldSkipEvent(event)) {\n      return null;\n    }\n    \n    // Privacy filtering\n    if (this.containsSensitiveData(event)) {\n      return this.sanitizeEvent(event);\n    }\n    \n    // Size limiting\n    if (this.isEventTooLarge(event)) {\n      return this.truncateEvent(event);\n    }\n    \n    return event;\n  }\n  \n  shouldSkipEvent(event) {\n    // Skip high-frequency, low-value events\n    if (event.type === 'mousemove' && Math.random() > 0.1) {\n      return true; // Only record 10% of mouse moves\n    }\n    \n    if (event.type === 'scroll' && Math.random() > 0.3) {\n      return true; // Only record 30% of scroll events\n    }\n    \n    return false;\n  }\n  \n  containsSensitiveData(event) {\n    if (event.target) {\n      const element = event.target;\n      return (\n        element.type === 'password' ||\n        element.autocomplete?.includes('cc-') ||\n        element.name?.includes('ssn') ||\n        element.className?.includes('sensitive')\n      );\n    }\n    return false;\n  }\n  \n  sanitizeEvent(event) {\n    // Create sanitized copy\n    const sanitized = { ...event };\n    \n    if (sanitized.value) {\n      sanitized.value = '*'.repeat(sanitized.value.length);\n    }\n    \n    if (sanitized.data && typeof sanitized.data === 'string') {\n      sanitized.data = sanitized.data.replace(/d{4,}/g, '****');\n    }\n    \n    return sanitized;\n  }\n  \n  isEventTooLarge(event) {\n    const eventSize = JSON.stringify(event).length;\n    return eventSize > 10000; // 10KB limit per event\n  }\n  \n  truncateEvent(event) {\n    const truncated = { ...event };\n    \n    if (truncated.data && truncated.data.length > 1000) {\n      truncated.data = truncated.data.substring(0, 1000) + '...';\n    }\n    \n    return truncated;\n  }\n  \n  setupEventListeners() {\n    // Monitor replay health\n    this.monitorReplayHealth();\n    \n    // Handle page visibility changes\n    document.addEventListener('visibilitychange', () => {\n      if (document.hidden) {\n        this.pauseRecording();\n      } else {\n        this.resumeRecording();\n      }\n    });\n    \n    // Handle low memory conditions\n    if ('memory' in performance) {\n      setInterval(() => {\n        if (performance.memory.usedJSHeapSize > 100 * 1024 * 1024) { // 100MB\n          this.optimizeForMemory();\n        }\n      }, 30000);\n    }\n  }\n  \n  monitorReplayHealth() {\n    setInterval(() => {\n      const replayData = this.getReplayMetrics();\n      \n      if (replayData.eventsPerSecond > 100) {\n        console.warn('High replay event rate detected:', replayData.eventsPerSecond);\n        this.throttleRecording();\n      }\n      \n      if (replayData.memoryUsage > 50 * 1024 * 1024) { // 50MB\n        console.warn('High replay memory usage:', replayData.memoryUsage);\n        this.optimizeForMemory();\n      }\n    }, 10000); // Check every 10 seconds\n  }\n  \n  getUserConsent() {\n    // Implement your consent management\n    return {\n      functional: localStorage.getItem('consent_functional') === 'true',\n      analytics: localStorage.getItem('consent_analytics') === 'true'\n    };\n  }\n  \n  pauseRecording() {\n    // Implement pause logic\n    console.log('Pausing session replay recording');\n  }\n  \n  resumeRecording() {\n    // Implement resume logic\n    console.log('Resuming session replay recording');\n  }\n  \n  throttleRecording() {\n    // Implement throttling logic\n    console.log('Throttling session replay recording');\n  }\n  \n  optimizeForMemory() {\n    // Implement memory optimization\n    console.log('Optimizing session replay for memory usage');\n  }\n  \n  getReplayMetrics() {\n    // Return current replay metrics\n    return {\n      eventsPerSecond: 10,\n      memoryUsage: 1024 * 1024, // 1MB\n      recordingDuration: 60000 // 1 minute\n    };\n  }\n}\n\n// Usage\nconst replayManager = new SessionReplayManager({\n  sessionSampleRate: 0.1,\n  errorSampleRate: 1.0\n});\n\nreplayManager.initialize();\n```\n\n### Framework-Specific Integration\n\n#### React Integration\n```javascript\n// React hook for session replay\nimport { useEffect, useCallback } from 'react';\nimport * as Sentry from '@sentry/browser';\n\nexport function useSessionReplay(options = {}) {\n  const {\n    enabled = true,\n    trackErrors = true,\n    trackUserActions = true,\n    privacyMode = 'moderate'\n  } = options;\n  \n  const startReplay = useCallback((sessionId) => {\n    if (!enabled) return;\n    \n    Sentry.addBreadcrumb({\n      message: 'Session replay started',\n      category: 'replay',\n      data: { sessionId }\n    });\n  }, [enabled]);\n  \n  const stopReplay = useCallback(() => {\n    if (!enabled) return;\n    \n    Sentry.addBreadcrumb({\n      message: 'Session replay stopped',\n      category: 'replay'\n    });\n  }, [enabled]);\n  \n  const captureUserAction = useCallback((action, data = {}) => {\n    if (!trackUserActions) return;\n    \n    Sentry.addBreadcrumb({\n      message: `User action: ${action}`,\n      category: 'user',\n      data\n    });\n  }, [trackUserActions]);\n  \n  useEffect(() => {\n    // Initialize replay on component mount\n    if (enabled) {\n      startReplay(`session_${Date.now()}`);\n    }\n    \n    return () => {\n      // Cleanup on unmount\n      stopReplay();\n    };\n  }, [enabled, startReplay, stopReplay]);\n  \n  return {\n    startReplay,\n    stopReplay,\n    captureUserAction\n  };\n}\n\n// Usage in React components\nfunction App() {\n  const { captureUserAction } = useSessionReplay({\n    enabled: process.env.NODE_ENV === 'production',\n    privacyMode: 'strict'\n  });\n  \n  const handleButtonClick = () => {\n    captureUserAction('button_click', {\n      button: 'primary_cta',\n      page: 'homepage'\n    });\n  };\n  \n  return (\n    <div>\n      <button onClick={handleButtonClick}>\n        Click me\n      </button>\n    </div>\n  );\n}\n```\n\n#### Vue.js Integration\n```javascript\n// Vue plugin for session replay\nimport * as Sentry from '@sentry/browser';\n\nexport default {\n  install(app, options = {}) {\n    const replayConfig = {\n      sessionSampleRate: options.sessionSampleRate || 0.1,\n      errorSampleRate: options.errorSampleRate || 1.0,\n      ...options\n    };\n    \n    // Initialize Sentry with replay\n    Sentry.init({\n      dsn: options.dsn,\n      integrations: [\n        new Sentry.Replay(replayConfig)\n      ]\n    });\n    \n    // Add global properties\n    app.config.globalProperties.$replay = {\n      captureUserAction: (action, data) => {\n        Sentry.addBreadcrumb({\n          message: `User action: ${action}`,\n          category: 'user',\n          data\n        });\n      },\n      \n      capturePageView: (route) => {\n        Sentry.addBreadcrumb({\n          message: `Page view: ${route.path}`,\n          category: 'navigation',\n          data: { route: route.name, params: route.params }\n        });\n      }\n    };\n    \n    // Global error handler\n    app.config.errorHandler = (error, instance, info) => {\n      Sentry.captureException(error, {\n        contexts: {\n          vue: {\n            componentName: instance?.$options.name,\n            errorInfo: info\n          }\n        }\n      });\n    };\n  }\n};\n\n// Usage in Vue app\nimport { createApp } from 'vue';\nimport SessionReplayPlugin from './plugins/session-replay';\n\nconst app = createApp(App);\n\napp.use(SessionReplayPlugin, {\n  dsn: process.env.VUE_APP_SENTRY_DSN,\n  sessionSampleRate: 0.1\n});\n```\n\n### Testing Session Replay\n\n#### Unit Testing\n```javascript\n// Mock session replay for testing\njest.mock('@sentry/browser', () => ({\n  init: jest.fn(),\n  addBreadcrumb: jest.fn(),\n  captureException: jest.fn(),\n  Replay: jest.fn().mockImplementation((config) => ({\n    config,\n    start: jest.fn(),\n    stop: jest.fn()\n  }))\n}));\n\ndescribe('SessionReplayManager', () => {\n  let replayManager;\n  \n  beforeEach(() => {\n    replayManager = new SessionReplayManager();\n  });\n  \n  it('should initialize with correct configuration', async () => {\n    const result = await replayManager.initialize();\n    \n    expect(result).toBe(true);\n    expect(Sentry.init).toHaveBeenCalledWith(\n      expect.objectContaining({\n        integrations: expect.arrayContaining([\n          expect.objectContaining({\n            config: expect.objectContaining({\n              sessionSampleRate: expect.any(Number)\n            })\n          })\n        ])\n      })\n    );\n  });\n  \n  it('should filter sensitive events', () => {\n    const sensitiveEvent = {\n      type: 'input',\n      target: { type: 'password' },\n      value: 'secret123'\n    };\n    \n    const filtered = replayManager.filterEvents(sensitiveEvent);\n    expect(filtered).toBeNull();\n  });\n});\n```\n\n#### E2E Testing with Replay Validation\n```javascript\n// Cypress test with replay validation\ndescribe('Checkout Flow with Replay', () => {\n  beforeEach(() => {\n    // Setup replay for testing\n    cy.window().then((win) => {\n      win.testReplayEvents = [];\n      \n      // Mock Sentry replay\n      win.Sentry = {\n        init: cy.stub(),\n        addBreadcrumb: cy.stub().callsFake((breadcrumb) => {\n          win.testReplayEvents.push(breadcrumb);\n        }),\n        captureException: cy.stub()\n      };\n    });\n  });\n  \n  it('should record user interactions during checkout', () => {\n    cy.visit('/checkout');\n    \n    // Perform checkout actions\n    cy.get('[data-testid=\"email-input\"]').type('user@example.com');\n    cy.get('[data-testid=\"continue-button\"]').click();\n    cy.get('[data-testid=\"payment-form\"]').should('be.visible');\n    \n    // Verify replay events were captured\n    cy.window().then((win) => {\n      expect(win.testReplayEvents).to.have.length.greaterThan(0);\n      \n      const userActions = win.testReplayEvents.filter(\n        event => event.category === 'user'\n      );\n      expect(userActions).to.have.length.greaterThan(2);\n    });\n  });\n  \n  it('should respect privacy settings', () => {\n    cy.visit('/checkout');\n    \n    // Type in password field\n    cy.get('[data-testid=\"password-input\"]').type('secretpassword');\n    \n    // Verify password input was not recorded\n    cy.window().then((win) => {\n      const inputEvents = win.testReplayEvents.filter(\n        event => event.message?.includes('input') && \n               event.data?.elementType === 'password'\n      );\n      expect(inputEvents).to.have.length(0);\n    });\n  });\n});\n```\n\n### Production Deployment\n\n#### Environment Configuration\n```javascript\n// Environment-specific configuration\nconst getReplayConfigForEnvironment = (env) => {\n  const configs = {\n    development: {\n      sessionSampleRate: 1.0,\n      errorSampleRate: 1.0,\n      maskAllText: false,\n      maskAllInputs: false,\n      debug: true\n    },\n    \n    staging: {\n      sessionSampleRate: 0.5,\n      errorSampleRate: 1.0,\n      maskAllText: false,\n      maskAllInputs: true,\n      debug: false\n    },\n    \n    production: {\n      sessionSampleRate: 0.05,\n      errorSampleRate: 1.0,\n      maskAllText: true,\n      maskAllInputs: true,\n      debug: false,\n      beforeSend: (event) => {\n        // Additional production filtering\n        delete event.user?.ip_address;\n        return event;\n      }\n    }\n  };\n  \n  return configs[env] || configs.production;\n};\n\n// Initialize with environment config\nconst config = getReplayConfigForEnvironment(process.env.NODE_ENV);\nconst replayManager = new SessionReplayManager(config);\n```\n\n#### Monitoring and Alerting\n```javascript\n// Production monitoring for replay health\nclass ReplayHealthMonitor {\n  constructor() {\n    this.metrics = {\n      eventRate: 0,\n      errorRate: 0,\n      memoryUsage: 0,\n      networkUsage: 0\n    };\n    \n    this.startMonitoring();\n  }\n  \n  startMonitoring() {\n    setInterval(() => {\n      this.collectMetrics();\n      this.checkThresholds();\n    }, 30000); // Every 30 seconds\n  }\n  \n  collectMetrics() {\n    // Collect replay performance metrics\n    this.metrics = {\n      eventRate: this.calculateEventRate(),\n      errorRate: this.calculateErrorRate(),\n      memoryUsage: this.getMemoryUsage(),\n      networkUsage: this.getNetworkUsage()\n    };\n  }\n  \n  checkThresholds() {\n    // Alert on high event rates\n    if (this.metrics.eventRate > 1000) {\n      this.sendAlert('high_event_rate', this.metrics.eventRate);\n    }\n    \n    // Alert on high memory usage\n    if (this.metrics.memoryUsage > 100 * 1024 * 1024) { // 100MB\n      this.sendAlert('high_memory_usage', this.metrics.memoryUsage);\n    }\n  }\n  \n  sendAlert(type, value) {\n    // Send alert to monitoring system\n    console.error(`Replay alert: ${type} = ${value}`);\n    \n    // Could integrate with your alerting system\n    // alertingService.send({ type, value, timestamp: Date.now() });\n  }\n  \n  calculateEventRate() {\n    // Implementation for calculating events per second\n    return 0;\n  }\n  \n  calculateErrorRate() {\n    // Implementation for calculating error rate\n    return 0;\n  }\n  \n  getMemoryUsage() {\n    if ('memory' in performance) {\n      return performance.memory.usedJSHeapSize;\n    }\n    return 0;\n  }\n  \n  getNetworkUsage() {\n    // Implementation for network usage tracking\n    return 0;\n  }\n}\n\n// Initialize health monitoring in production\nif (process.env.NODE_ENV === 'production') {\n  new ReplayHealthMonitor();\n}\n```\n\nThis comprehensive setup guide covers all aspects of implementing session replay, from basic configuration to advanced production deployment strategies, ensuring you can capture valuable user session data while maintaining privacy and performance standards.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.738Z",
    "updatedAt": "2025-06-02T06:59:22.153Z"
  },
  {
    "id": "oyhjk1tt5dqfbyfrhkry3dhq",
    "courseId": "xzf8dsrwmu8jhzvj12perj95",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Privacy and Data Protection\n\n## Understanding Privacy in Session Replay\n\nPrivacy and data protection are fundamental considerations when implementing session replay. This lesson covers comprehensive strategies for maintaining user privacy while maximizing the value of session replay data.\n\n## Privacy by Design Principles\n\n### Core Privacy Principles\n\n#### 1. Data Minimization\nOnly collect the data you need for your specific use case:\n\n```javascript\n// Implement selective recording based on page type\nclass PrivacyAwareReplay {\n  constructor() {\n    this.sensitivePages = [\n      '/payment',\n      '/checkout',\n      '/profile',\n      '/settings',\n      '/admin'\n    ];\n    \n    this.publicPages = [\n      '/',\n      '/about',\n      '/contact',\n      '/blog'\n    ];\n  }\n  \n  shouldRecordPage(path) {\n    // Don't record sensitive pages\n    if (this.sensitivePages.some(page => path.startsWith(page))) {\n      return false;\n    }\n    \n    // Record public pages with lower sampling\n    if (this.publicPages.some(page => path.startsWith(page))) {\n      return Math.random() < 0.05; // 5% sampling\n    }\n    \n    // Default behavior for other pages\n    return Math.random() < 0.02; // 2% sampling\n  }\n  \n  getConfigForPage(path) {\n    if (!this.shouldRecordPage(path)) {\n      return { sessionSampleRate: 0 };\n    }\n    \n    const baseConfig = {\n      sessionSampleRate: 0.02,\n      errorSampleRate: 1.0,\n      maskAllText: true,\n      maskAllInputs: true,\n      blockAllMedia: true\n    };\n    \n    // Enhanced privacy for sensitive areas\n    if (this.sensitivePages.some(page => path.startsWith(page))) {\n      return {\n        ...baseConfig,\n        sessionSampleRate: 0,\n        beforeAddRecordingEvent: () => null // Block all events\n      };\n    }\n    \n    return baseConfig;\n  }\n}\n\n// Usage with dynamic configuration\nconst privacyReplay = new PrivacyAwareReplay();\n\nfunction initializeReplayForPage() {\n  const currentPath = window.location.pathname;\n  const config = privacyReplay.getConfigForPage(currentPath);\n  \n  if (config.sessionSampleRate > 0) {\n    Sentry.init({\n      dsn: process.env.REACT_APP_SENTRY_DSN,\n      integrations: [new Sentry.Replay(config)]\n    });\n  }\n}\n```\n\n#### 2. Purpose Limitation\nClearly define and limit the purposes for which replay data is used:\n\n```javascript\n// Purpose-specific replay configurations\nconst REPLAY_PURPOSES = {\n  BUG_FIXING: {\n    sessionSampleRate: 0.01,\n    errorSampleRate: 1.0,\n    maskAllText: true,\n    maskAllInputs: true,\n    maxReplayDuration: 300000, // 5 minutes\n    tags: { purpose: 'debugging' },\n    retention: '30_days'\n  },\n  \n  UX_RESEARCH: {\n    sessionSampleRate: 0.05,\n    errorSampleRate: 0.1,\n    maskAllText: false,\n    maskAllInputs: true,\n    recordCanvas: true,\n    tags: { purpose: 'ux_research' },\n    retention: '90_days'\n  },\n  \n  CUSTOMER_SUPPORT: {\n    sessionSampleRate: 0,\n    errorSampleRate: 0.5,\n    maskAllText: true,\n    maskAllInputs: true,\n    requiresUserConsent: true,\n    tags: { purpose: 'support' },\n    retention: '7_days'\n  }\n};\n\nfunction initializeReplayForPurpose(purpose, userConsent = {}) {\n  const config = REPLAY_PURPOSES[purpose];\n  \n  if (!config) {\n    throw new Error(`Unknown replay purpose: ${purpose}`);\n  }\n  \n  // Check consent requirements\n  if (config.requiresUserConsent && !userConsent.explicit) {\n    config.sessionSampleRate = 0;\n  }\n  \n  return new Sentry.Replay({\n    ...config,\n    beforeSend: (event) => {\n      // Add purpose metadata\n      event.tags = { ...event.tags, ...config.tags };\n      event.extra = {\n        ...event.extra,\n        retention_policy: config.retention,\n        purpose: purpose\n      };\n      return event;\n    }\n  });\n}\n```\n\n## Data Masking and Blocking\n\n### Advanced Masking Strategies\n\n#### Intelligent Text Masking\n```javascript\n// Smart text masking based on content analysis\nclass IntelligentTextMasker {\n  constructor() {\n    this.patterns = {\n      email: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+.[A-Z|a-z]{2,}\b/g,\n      phone: /(+?d{1,4}[s-]?)?(?d{3})?[s-]?d{3}[s-]?d{4}/g,\n      ssn: /\bd{3}-d{2}-d{4}\b/g,\n      creditCard: /\bd{4}[s-]?d{4}[s-]?d{4}[s-]?d{4}\b/g,\n      ipAddress: /\bd{1,3}.d{1,3}.d{1,3}.d{1,3}\b/g,\n      uuid: /\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\b/gi\n    };\n    \n    this.sensitiveKeywords = [\n      'password', 'secret', 'token', 'key', 'auth',\n      'private', 'confidential', 'sensitive', 'personal'\n    ];\n  }\n  \n  maskText(text, element) {\n    if (!text || typeof text !== 'string') return text;\n    \n    // Check if element or its parents have sensitive indicators\n    if (this.isElementSensitive(element)) {\n      return '*'.repeat(text.length);\n    }\n    \n    // Apply pattern-based masking\n    let maskedText = text;\n    \n    Object.entries(this.patterns).forEach(([type, pattern]) => {\n      maskedText = maskedText.replace(pattern, (match) => {\n        return this.getMaskForType(type, match);\n      });\n    });\n    \n    return maskedText;\n  }\n  \n  isElementSensitive(element) {\n    if (!element) return false;\n    \n    // Check element and its parents for sensitive indicators\n    let current = element;\n    while (current && current !== document.body) {\n      // Check attributes\n      const sensitiveAttrs = ['data-sensitive', 'data-private', 'data-confidential'];\n      if (sensitiveAttrs.some(attr => current.hasAttribute(attr))) {\n        return true;\n      }\n      \n      // Check class names\n      const className = current.className || '';\n      if (this.sensitiveKeywords.some(keyword => \n        className.toLowerCase().includes(keyword))) {\n        return true;\n      }\n      \n      // Check input types\n      if (current.type && ['password', 'email'].includes(current.type)) {\n        return true;\n      }\n      \n      current = current.parentElement;\n    }\n    \n    return false;\n  }\n  \n  getMaskForType(type, original) {\n    const masks = {\n      email: 'u***@***.com',\n      phone: '***-***-****',\n      ssn: '***-**-****',\n      creditCard: '****-****-****-****',\n      ipAddress: '***.***.***.***',\n      uuid: '********-****-****-****-************'\n    };\n    \n    return masks[type] || '*'.repeat(original.length);\n  }\n}\n\n// Integration with Sentry Replay\nconst textMasker = new IntelligentTextMasker();\n\nconst privacyReplay = new Sentry.Replay({\n  maskAllText: false, // We'll handle masking manually\n  beforeAddRecordingEvent: (event) => {\n    if (event.type === 'text' || event.type === 'input') {\n      const maskedValue = textMasker.maskText(event.value, event.target);\n      return {\n        ...event,\n        value: maskedValue\n      };\n    }\n    return event;\n  }\n});\n```\n\n#### Dynamic Element Blocking\n```javascript\n// Dynamic blocking based on content and context\nclass DynamicElementBlocker {\n  constructor() {\n    this.blockingRules = [\n      {\n        name: 'payment_forms',\n        selector: 'form[data-payment], .payment-form, #payment',\n        reason: 'Contains payment information'\n      },\n      {\n        name: 'user_profiles',\n        selector: '.user-profile, .profile-info, [data-user-info]',\n        reason: 'Contains personal information'\n      },\n      {\n        name: 'admin_panels',\n        selector: '.admin-panel, [role=\"admin\"], .admin-content',\n        reason: 'Administrative interface'\n      },\n      {\n        name: 'sensitive_inputs',\n        selector: 'input[type=\"password\"], input[name*=\"ssn\"], input[name*=\"credit\"]',\n        reason: 'Sensitive input fields'\n      }\n    ];\n    \n    this.dynamicRules = [];\n  }\n  \n  addDynamicRule(selector, reason, condition = () => true) {\n    this.dynamicRules.push({\n      selector,\n      reason,\n      condition,\n      timestamp: Date.now()\n    });\n  }\n  \n  getBlockedElements() {\n    const blocked = [];\n    \n    // Apply static rules\n    this.blockingRules.forEach(rule => {\n      const elements = document.querySelectorAll(rule.selector);\n      elements.forEach(element => {\n        blocked.push({\n          element,\n          reason: rule.reason,\n          rule: rule.name\n        });\n      });\n    });\n    \n    // Apply dynamic rules\n    this.dynamicRules.forEach(rule => {\n      if (rule.condition()) {\n        const elements = document.querySelectorAll(rule.selector);\n        elements.forEach(element => {\n          blocked.push({\n            element,\n            reason: rule.reason,\n            rule: 'dynamic'\n          });\n        });\n      }\n    });\n    \n    return blocked;\n  }\n  \n  createBlockingSelectors() {\n    const blockedElements = this.getBlockedElements();\n    return blockedElements.map(({ element }) => {\n      // Generate unique selector for element\n      return this.generateSelector(element);\n    });\n  }\n  \n  generateSelector(element) {\n    if (element.id) {\n      return `#${element.id}`;\n    }\n    \n    if (element.className) {\n      const classes = element.className.split(' ').filter(Boolean);\n      if (classes.length > 0) {\n        return `.${classes.join('.')}`;\n      }\n    }\n    \n    // Fallback to tag name with nth-child\n    const parent = element.parentElement;\n    if (parent) {\n      const siblings = Array.from(parent.children);\n      const index = siblings.indexOf(element) + 1;\n      return `${element.tagName.toLowerCase()}:nth-child(${index})`;\n    }\n    \n    return element.tagName.toLowerCase();\n  }\n  \n  // Context-aware blocking\n  addContextualBlocking() {\n    // Block elements based on URL patterns\n    const currentPath = window.location.pathname;\n    \n    if (currentPath.includes('/checkout')) {\n      this.addDynamicRule(\n        '.payment-method, .billing-address',\n        'Checkout page payment information'\n      );\n    }\n    \n    if (currentPath.includes('/profile')) {\n      this.addDynamicRule(\n        '.personal-info, .contact-details',\n        'User profile information'\n      );\n    }\n    \n    // Block based on user authentication state\n    const isAuthenticated = this.checkAuthenticationState();\n    if (isAuthenticated) {\n      this.addDynamicRule(\n        '.user-specific-content',\n        'Authenticated user content'\n      );\n    }\n  }\n  \n  checkAuthenticationState() {\n    // Check for authentication indicators\n    return (\n      localStorage.getItem('authToken') ||\n      document.cookie.includes('session') ||\n      document.querySelector('[data-authenticated]')\n    );\n  }\n}\n\n// Usage with Sentry Replay\nconst elementBlocker = new DynamicElementBlocker();\nelementBlocker.addContextualBlocking();\n\nconst privacyReplay = new Sentry.Replay({\n  block: elementBlocker.createBlockingSelectors(),\n  beforeAddRecordingEvent: (event) => {\n    // Re-evaluate blocking rules for dynamic content\n    const currentBlocked = elementBlocker.createBlockingSelectors();\n    \n    if (event.target && currentBlocked.some(selector => {\n      try {\n        return event.target.matches(selector);\n      } catch (e) {\n        return false;\n      }\n    })) {\n      return null; // Block this event\n    }\n    \n    return event;\n  }\n});\n```\n\n## Consent Management\n\n### GDPR-Compliant Consent System\n```javascript\n// Comprehensive consent management for session replay\nclass ConsentManager {\n  constructor() {\n    this.consentTypes = {\n      necessary: {\n        required: true,\n        description: 'Essential for website functionality',\n        includes: ['error tracking for critical bugs']\n      },\n      functional: {\n        required: false,\n        description: 'Improves website functionality',\n        includes: ['session replay for debugging']\n      },\n      analytics: {\n        required: false,\n        description: 'Helps us understand user behavior',\n        includes: ['detailed session replay', 'user journey analysis']\n      }\n    };\n    \n    this.consent = this.loadConsent();\n  }\n  \n  loadConsent() {\n    const stored = localStorage.getItem('privacy_consent');\n    if (stored) {\n      try {\n        const parsed = JSON.parse(stored);\n        // Check if consent is still valid (e.g., within 12 months)\n        if (Date.now() - parsed.timestamp < 365 * 24 * 60 * 60 * 1000) {\n          return parsed;\n        }\n      } catch (e) {\n        console.error('Failed to parse stored consent:', e);\n      }\n    }\n    \n    return {\n      necessary: true,\n      functional: false,\n      analytics: false,\n      timestamp: 0,\n      version: 0\n    };\n  }\n  \n  saveConsent(consentChoices) {\n    const consentData = {\n      ...consentChoices,\n      timestamp: Date.now(),\n      version: this.getCurrentConsentVersion(),\n      userAgent: navigator.userAgent,\n      ip: this.getClientIP() // In practice, get from server\n    };\n    \n    localStorage.setItem('privacy_consent', JSON.stringify(consentData));\n    this.consent = consentData;\n    \n    // Update replay configuration based on new consent\n    this.updateReplayConfig();\n    \n    // Log consent change for audit trail\n    this.logConsentChange(consentData);\n  }\n  \n  getCurrentConsentVersion() {\n    return 1; // Increment when privacy policy changes\n  }\n  \n  hasConsent(type) {\n    return this.consent[type] === true;\n  }\n  \n  requiresConsentPrompt() {\n    return (\n      this.consent.timestamp === 0 ||\n      this.consent.version < this.getCurrentConsentVersion() ||\n      this.isConsentExpired()\n    );\n  }\n  \n  isConsentExpired() {\n    const maxAge = 365 * 24 * 60 * 60 * 1000; // 1 year\n    return Date.now() - this.consent.timestamp > maxAge;\n  }\n  \n  getReplayConfigFromConsent() {\n    if (!this.hasConsent('functional')) {\n      return {\n        sessionSampleRate: 0,\n        errorSampleRate: this.hasConsent('necessary') ? 0.1 : 0\n      };\n    }\n    \n    const baseConfig = {\n      sessionSampleRate: 0.02,\n      errorSampleRate: 1.0,\n      maskAllText: !this.hasConsent('analytics'),\n      maskAllInputs: true,\n      blockAllMedia: !this.hasConsent('analytics')\n    };\n    \n    if (this.hasConsent('analytics')) {\n      return {\n        ...baseConfig,\n        sessionSampleRate: 0.05,\n        recordCanvas: true,\n        collectFonts: true,\n        networkDetailAllowed: true\n      };\n    }\n    \n    return baseConfig;\n  }\n  \n  updateReplayConfig() {\n    const config = this.getReplayConfigFromConsent();\n    \n    // Reinitialize Sentry with new config\n    Sentry.init({\n      dsn: process.env.REACT_APP_SENTRY_DSN,\n      integrations: [new Sentry.Replay(config)]\n    });\n    \n    // Log configuration change\n    Sentry.addBreadcrumb({\n      message: 'Replay configuration updated based on consent',\n      category: 'consent',\n      data: { hasAnalyticsConsent: this.hasConsent('analytics') }\n    });\n  }\n  \n  logConsentChange(consentData) {\n    // Log consent changes for compliance audit\n    Sentry.addBreadcrumb({\n      message: 'User consent updated',\n      category: 'privacy',\n      data: {\n        consentTypes: Object.keys(consentData).filter(key => \n          consentData[key] === true && key !== 'timestamp' && key !== 'version'\n        ),\n        timestamp: consentData.timestamp,\n        version: consentData.version\n      },\n      level: 'info'\n    });\n  }\n  \n  showConsentPrompt() {\n    return new Promise((resolve) => {\n      const modal = this.createConsentModal(resolve);\n      document.body.appendChild(modal);\n    });\n  }\n  \n  createConsentModal(onResolve) {\n    const modal = document.createElement('div');\n    modal.className = 'consent-modal';\n    modal.innerHTML = `\n      <div class=\"consent-modal-backdrop\">\n        <div class=\"consent-modal-content\">\n          <h2>Privacy & Cookie Settings</h2>\n          <p>We use session replay to improve our website and fix bugs. Please choose your preferences:</p>\n          \n          <div class=\"consent-options\">\n            <div class=\"consent-option\">\n              <label>\n                <input type=\"checkbox\" name=\"necessary\" checked disabled>\n                <strong>Necessary</strong> - Essential website functionality\n              </label>\n              <p>Required for error tracking and basic functionality.</p>\n            </div>\n            \n            <div class=\"consent-option\">\n              <label>\n                <input type=\"checkbox\" name=\"functional\" id=\"functional-consent\">\n                <strong>Functional</strong> - Session replay for debugging\n              </label>\n              <p>Helps us identify and fix issues you encounter.</p>\n            </div>\n            \n            <div class=\"consent-option\">\n              <label>\n                <input type=\"checkbox\" name=\"analytics\" id=\"analytics-consent\">\n                <strong>Analytics</strong> - Detailed usage analysis\n              </label>\n              <p>Provides insights into how our website is used to improve user experience.</p>\n            </div>\n          </div>\n          \n          <div class=\"consent-actions\">\n            <button id=\"accept-selected\">Accept Selected</button>\n            <button id=\"accept-all\">Accept All</button>\n            <button id=\"reject-optional\">Only Necessary</button>\n          </div>\n          \n          <p class=\"consent-footer\">\n            <a href=\"/privacy-policy\" target=\"_blank\">Privacy Policy</a> | \n            <a href=\"/cookie-policy\" target=\"_blank\">Cookie Policy</a>\n          </p>\n        </div>\n      </div>\n    `;\n    \n    // Add event listeners\n    modal.querySelector('#accept-selected').addEventListener('click', () => {\n      const functional = modal.querySelector('#functional-consent').checked;\n      const analytics = modal.querySelector('#analytics-consent').checked;\n      \n      this.saveConsent({\n        necessary: true,\n        functional,\n        analytics\n      });\n      \n      document.body.removeChild(modal);\n      onResolve({ functional, analytics });\n    });\n    \n    modal.querySelector('#accept-all').addEventListener('click', () => {\n      this.saveConsent({\n        necessary: true,\n        functional: true,\n        analytics: true\n      });\n      \n      document.body.removeChild(modal);\n      onResolve({ functional: true, analytics: true });\n    });\n    \n    modal.querySelector('#reject-optional').addEventListener('click', () => {\n      this.saveConsent({\n        necessary: true,\n        functional: false,\n        analytics: false\n      });\n      \n      document.body.removeChild(modal);\n      onResolve({ functional: false, analytics: false });\n    });\n    \n    return modal;\n  }\n  \n  getClientIP() {\n    // In practice, this should be handled server-side\n    return 'xxx.xxx.xxx.xxx';\n  }\n}\n\n// Usage\nconst consentManager = new ConsentManager();\n\nasync function initializePrivacyCompliantReplay() {\n  if (consentManager.requiresConsentPrompt()) {\n    await consentManager.showConsentPrompt();\n  }\n  \n  const config = consentManager.getReplayConfigFromConsent();\n  \n  if (config.sessionSampleRate > 0) {\n    Sentry.init({\n      dsn: process.env.REACT_APP_SENTRY_DSN,\n      integrations: [new Sentry.Replay(config)]\n    });\n  }\n}\n\n// Initialize on page load\ninitializePrivacyCompliantReplay();\n```\n\n## Data Retention and Deletion\n\n### Automated Data Lifecycle Management\n```javascript\n// Data retention policy implementation\nclass DataRetentionManager {\n  constructor() {\n    this.retentionPolicies = {\n      debugging: {\n        duration: 30 * 24 * 60 * 60 * 1000, // 30 days\n        autoDelete: true,\n        compressionAfter: 7 * 24 * 60 * 60 * 1000 // 7 days\n      },\n      \n      analytics: {\n        duration: 90 * 24 * 60 * 60 * 1000, // 90 days\n        autoDelete: true,\n        anonymizeAfter: 30 * 24 * 60 * 60 * 1000 // 30 days\n      },\n      \n      legal_hold: {\n        duration: 365 * 24 * 60 * 60 * 1000, // 1 year\n        autoDelete: false,\n        requiresManualReview: true\n      }\n    };\n  }\n  \n  tagReplayWithRetention(purpose, userConsent = {}) {\n    const policy = this.retentionPolicies[purpose];\n    if (!policy) {\n      throw new Error(`Unknown retention purpose: ${purpose}`);\n    }\n    \n    return {\n      beforeSend: (event) => {\n        event.extra = {\n          ...event.extra,\n          retention: {\n            purpose,\n            policy: policy.duration,\n            created_at: Date.now(),\n            auto_delete: policy.autoDelete,\n            user_consent: userConsent,\n            anonymize_after: policy.anonymizeAfter\n          }\n        };\n        \n        return event;\n      }\n    };\n  }\n  \n  requestDataDeletion(userId, reason = 'user_request') {\n    // Implementation would integrate with your data processing system\n    const deletionRequest = {\n      userId,\n      reason,\n      timestamp: Date.now(),\n      type: 'session_replay_data',\n      status: 'pending'\n    };\n    \n    // Log deletion request for audit trail\n    Sentry.addBreadcrumb({\n      message: 'Data deletion requested',\n      category: 'privacy',\n      data: deletionRequest,\n      level: 'info'\n    });\n    \n    return this.processDataDeletion(deletionRequest);\n  }\n  \n  async processDataDeletion(request) {\n    try {\n      // In practice, this would call your data processing API\n      console.log('Processing data deletion request:', request);\n      \n      // Update request status\n      request.status = 'completed';\n      request.completedAt = Date.now();\n      \n      return request;\n    } catch (error) {\n      request.status = 'failed';\n      request.error = error.message;\n      throw error;\n    }\n  }\n  \n  scheduleAutomaticCleanup() {\n    // Schedule periodic cleanup based on retention policies\n    setInterval(() => {\n      this.performCleanup();\n    }, 24 * 60 * 60 * 1000); // Daily cleanup\n  }\n  \n  async performCleanup() {\n    console.log('Performing scheduled data cleanup...');\n    \n    // This would typically run server-side\n    // Implementation would query and delete expired replay data\n    \n    Sentry.addBreadcrumb({\n      message: 'Automated data cleanup performed',\n      category: 'data_management',\n      data: {\n        timestamp: Date.now(),\n        policies_applied: Object.keys(this.retentionPolicies)\n      }\n    });\n  }\n}\n\n// Usage\nconst retentionManager = new DataRetentionManager();\n\n// Initialize replay with retention policy\nconst replayWithRetention = new Sentry.Replay({\n  sessionSampleRate: 0.1,\n  errorSampleRate: 1.0,\n  ...retentionManager.tagReplayWithRetention('debugging', {\n    functional: true,\n    analytics: false\n  })\n});\n```\n\n## Compliance and Auditing\n\n### Audit Trail Implementation\n```javascript\n// Comprehensive audit trail for privacy compliance\nclass PrivacyAuditLogger {\n  constructor() {\n    this.auditEvents = [];\n    this.maxEvents = 1000;\n  }\n  \n  logEvent(type, data, userId = null) {\n    const event = {\n      id: this.generateEventId(),\n      type,\n      userId,\n      data,\n      timestamp: Date.now(),\n      sessionId: this.getSessionId(),\n      userAgent: navigator.userAgent,\n      url: window.location.href\n    };\n    \n    this.auditEvents.push(event);\n    \n    // Keep only recent events\n    if (this.auditEvents.length > this.maxEvents) {\n      this.auditEvents = this.auditEvents.slice(-this.maxEvents);\n    }\n    \n    // Send to audit system\n    this.sendToAuditSystem(event);\n  }\n  \n  logConsentChange(oldConsent, newConsent, userId) {\n    this.logEvent('consent_change', {\n      old_consent: oldConsent,\n      new_consent: newConsent,\n      changes: this.getConsentChanges(oldConsent, newConsent)\n    }, userId);\n  }\n  \n  logDataAccess(dataType, purpose, userId) {\n    this.logEvent('data_access', {\n      data_type: dataType,\n      purpose,\n      access_method: 'session_replay'\n    }, userId);\n  }\n  \n  logDataDeletion(userId, reason, dataTypes) {\n    this.logEvent('data_deletion', {\n      reason,\n      data_types: dataTypes,\n      initiated_by: 'user'\n    }, userId);\n  }\n  \n  logPrivacyViolation(violationType, details, userId) {\n    this.logEvent('privacy_violation', {\n      violation_type: violationType,\n      details,\n      severity: 'high'\n    }, userId);\n    \n    // Also send to Sentry for immediate attention\n    Sentry.captureMessage(`Privacy violation detected: ${violationType}`, {\n      level: 'error',\n      extra: details,\n      user: { id: userId }\n    });\n  }\n  \n  getConsentChanges(oldConsent, newConsent) {\n    const changes = {};\n    \n    Object.keys(newConsent).forEach(key => {\n      if (oldConsent[key] !== newConsent[key]) {\n        changes[key] = {\n          from: oldConsent[key],\n          to: newConsent[key]\n        };\n      }\n    });\n    \n    return changes;\n  }\n  \n  generateEventId() {\n    return 'audit_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);\n  }\n  \n  getSessionId() {\n    return Sentry.getCurrentHub().getScope()?.getTransaction()?.traceId || 'unknown';\n  }\n  \n  sendToAuditSystem(event) {\n    // In practice, send to your audit/compliance system\n    console.log('Audit event:', event);\n    \n    // Could also store in local storage for offline capability\n    const stored = JSON.parse(localStorage.getItem('audit_events') || '[]');\n    stored.push(event);\n    \n    // Keep only recent events in storage\n    if (stored.length > 100) {\n      stored.splice(0, stored.length - 100);\n    }\n    \n    localStorage.setItem('audit_events', JSON.stringify(stored));\n  }\n  \n  generateComplianceReport() {\n    const report = {\n      report_id: this.generateEventId(),\n      generated_at: Date.now(),\n      period: {\n        start: Date.now() - (30 * 24 * 60 * 60 * 1000), // Last 30 days\n        end: Date.now()\n      },\n      metrics: this.calculateComplianceMetrics(),\n      violations: this.getViolations(),\n      consent_analytics: this.analyzeConsentPatterns()\n    };\n    \n    return report;\n  }\n  \n  calculateComplianceMetrics() {\n    const recentEvents = this.auditEvents.filter(\n      event => event.timestamp > Date.now() - (30 * 24 * 60 * 60 * 1000)\n    );\n    \n    return {\n      total_events: recentEvents.length,\n      consent_changes: recentEvents.filter(e => e.type === 'consent_change').length,\n      data_deletions: recentEvents.filter(e => e.type === 'data_deletion').length,\n      privacy_violations: recentEvents.filter(e => e.type === 'privacy_violation').length,\n      data_access_events: recentEvents.filter(e => e.type === 'data_access').length\n    };\n  }\n  \n  getViolations() {\n    return this.auditEvents\n      .filter(event => event.type === 'privacy_violation')\n      .map(event => ({\n        id: event.id,\n        timestamp: event.timestamp,\n        type: event.data.violation_type,\n        severity: event.data.severity\n      }));\n  }\n  \n  analyzeConsentPatterns() {\n    const consentEvents = this.auditEvents.filter(e => e.type === 'consent_change');\n    \n    return {\n      total_consent_changes: consentEvents.length,\n      opt_in_rate: this.calculateOptInRate(consentEvents),\n      opt_out_rate: this.calculateOptOutRate(consentEvents),\n      most_common_changes: this.getMostCommonConsentChanges(consentEvents)\n    };\n  }\n  \n  calculateOptInRate(events) {\n    const optIns = events.filter(event => \n      Object.values(event.data.changes).some(change => \n        !change.from && change.to\n      )\n    );\n    \n    return events.length > 0 ? optIns.length / events.length : 0;\n  }\n  \n  calculateOptOutRate(events) {\n    const optOuts = events.filter(event => \n      Object.values(event.data.changes).some(change => \n        change.from && !change.to\n      )\n    );\n    \n    return events.length > 0 ? optOuts.length / events.length : 0;\n  }\n  \n  getMostCommonConsentChanges(events) {\n    const changeTypes = {};\n    \n    events.forEach(event => {\n      Object.keys(event.data.changes).forEach(changeType => {\n        changeTypes[changeType] = (changeTypes[changeType] || 0) + 1;\n      });\n    });\n    \n    return Object.entries(changeTypes)\n      .sort(([,a], [,b]) => b - a)\n      .slice(0, 5);\n  }\n}\n\n// Usage\nconst auditLogger = new PrivacyAuditLogger();\n\n// Integration with consent manager\nconst enhancedConsentManager = new ConsentManager();\nenhancedConsentManager.onConsentChange = (oldConsent, newConsent, userId) => {\n  auditLogger.logConsentChange(oldConsent, newConsent, userId);\n};\n\n// Integration with replay initialization\nfunction initializeAuditedReplay() {\n  auditLogger.logDataAccess('session_replay', 'debugging', 'current_user');\n  \n  // Initialize replay with audit logging\n  const replay = new Sentry.Replay({\n    sessionSampleRate: 0.1,\n    errorSampleRate: 1.0,\n    beforeAddRecordingEvent: (event) => {\n      // Log potentially sensitive data access\n      if (event.type === 'input' && event.target?.type === 'email') {\n        auditLogger.logDataAccess('email_input', 'session_replay', 'current_user');\n      }\n      \n      return event;\n    }\n  });\n  \n  return replay;\n}\n```\n\nThis comprehensive privacy and data protection framework ensures that your session replay implementation respects user privacy, complies with regulations like GDPR, and maintains detailed audit trails for compliance reporting. The modular design allows you to customize privacy controls based on your specific requirements and regulatory environment.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.809Z",
    "updatedAt": "2025-06-02T06:59:22.227Z"
  },
  {
    "id": "i9bn0xq2o92zdmeroripdr1s",
    "courseId": "wcja6u9fuk2edvmcvjr16zyd",
    "title": "Introduction to Basics of Error Monitoring",
    "slug": "introduction-to-basics-of-error-monitoring",
    "description": "Get started with Basics of Error Monitoring",
    "type": "text",
    "content": "# Introduction to Error Monitoring\n\n## What is Error Monitoring?\n\nError monitoring is the practice of automatically detecting, collecting, and analyzing errors that occur in software applications. Think of it as having a vigilant assistant that never sleeps, constantly watching your application and immediately alerting you when something goes wrong.\n\nUnlike traditional logging, which often requires developers to manually sift through log files to find problems, error monitoring provides structured, actionable insights about application failures in real-time.\n\n## Why Error Monitoring Matters\n\n### The Cost of Undetected Errors\n\nEvery unhandled error in production has potential consequences:\n\n- **User Experience**: Broken features frustrate users and can lead to abandonment\n- **Business Impact**: Failed transactions directly affect revenue\n- **Reputation Damage**: Poor application reliability erodes user trust\n- **Development Efficiency**: Time spent firefighting could be used building new features\n\n### The Traditional Problem\n\nBefore modern error monitoring, development teams faced several challenges:\n\n1. **Reactive Approach**: Teams only learned about issues when users complained\n2. **Incomplete Information**: Error reports from users were often vague or missing context\n3. **Difficult Reproduction**: Without proper context, reproducing bugs was time-consuming\n4. **Hidden Issues**: Many errors went completely unnoticed, silently degrading user experience\n\n## Core Concepts\n\n### What Gets Monitored\n\nError monitoring systems track various types of application failures:\n\n**JavaScript Errors**\n- Syntax errors in code\n- Reference errors (accessing undefined variables)\n- Type errors (calling methods on wrong data types)\n- Network request failures\n\n**Backend Errors**\n- Server crashes and exceptions\n- Database connection failures\n- API timeouts and rate limiting\n- Third-party service integration issues\n\n**Performance Issues**\n- Slow database queries\n- Memory leaks\n- High CPU usage\n- Network latency problems\n\n### Error Context and Metadata\n\nModern error monitoring goes beyond just capturing the error message. It collects valuable context:\n\n**Technical Context**\n- Stack trace showing exactly where the error occurred\n- Browser version and operating system\n- Device type and screen resolution\n- Network conditions\n\n**User Context**\n- User ID and session information\n- Actions leading up to the error\n- Current page or feature being used\n- User's location and timezone\n\n**Application Context**\n- Release version and deployment information\n- Feature flags and A/B test variants\n- Custom tags and metadata\n- Related database records or API calls\n\n## The Error Monitoring Workflow\n\n### Detection\nErrors are automatically captured as they occur, without requiring manual intervention. This includes both handled errors (caught by try-catch blocks) and unhandled errors that would otherwise crash the application.\n\n### Aggregation\nSimilar errors are grouped together to prevent notification spam. Instead of receiving 100 individual alerts for the same bug, you get one notification with a count showing how many users were affected.\n\n### Prioritization\nNot all errors are equally important. Error monitoring systems help prioritize issues based on:\n- Number of affected users\n- Frequency of occurrence\n- Business impact of the affected feature\n- Severity of the error type\n\n### Notification\nTeams receive alerts through their preferred channels (email, Slack, PagerDuty) when new issues are detected or when existing issues cross certain thresholds.\n\n### Resolution\nWith proper context and stack traces, developers can quickly identify the root cause and deploy fixes. The monitoring system tracks when issues are resolved and can alert if they reoccur.\n\n## Types of Error Monitoring\n\n### Real User Monitoring (RUM)\nCaptures errors experienced by actual users in production environments. This provides the most accurate picture of user experience but may miss edge cases that only occur under specific conditions.\n\n### Synthetic Monitoring\nUses automated scripts to continuously test application functionality, catching issues before they affect real users. This is particularly useful for monitoring critical user journeys like signup flows or payment processing.\n\n### Performance Monitoring\nTracks application performance metrics alongside errors, helping identify when slow performance might be causing user frustration even without explicit errors.\n\n## Building an Error Monitoring Strategy\n\n### Start with Critical Paths\nBegin monitoring the most important user journeys in your application:\n- User registration and login\n- Payment and checkout processes\n- Core feature functionality\n- API endpoints with high usage\n\n### Establish Baselines\nBefore you can identify problems, you need to understand what \"normal\" looks like:\n- Average error rates for different parts of your application\n- Typical performance metrics\n- Expected user behavior patterns\n\n### Define Success Metrics\nDetermine how you'll measure the effectiveness of your error monitoring:\n- Mean time to detection (MTTD)\n- Mean time to resolution (MTTR)\n- User-reported issues vs. system-detected issues\n- Overall application stability trends\n\n## Common Challenges and Solutions\n\n### Alert Fatigue\n**Problem**: Too many notifications can overwhelm teams and cause important alerts to be ignored.\n\n**Solution**: \n- Set appropriate thresholds for notifications\n- Use error grouping to reduce noise\n- Implement escalation rules for critical issues\n- Regularly review and adjust alert sensitivity\n\n### False Positives\n**Problem**: Errors that appear serious but don't actually impact users.\n\n**Solution**:\n- Add proper error handling for expected failure scenarios\n- Use filtering rules to exclude non-actionable errors\n- Implement proper error classification\n- Monitor user impact metrics alongside error counts\n\n### Context Loss\n**Problem**: Errors without sufficient context are difficult to debug and resolve.\n\n**Solution**:\n- Capture relevant user and application state\n- Include breadcrumbs showing user actions before errors\n- Add custom tags and metadata for business context\n- Integrate with other observability tools for full picture\n\n## Best Practices for Beginners\n\n### 1. Start Simple\nDon't try to monitor everything at once. Begin with basic error detection for your most critical features and gradually expand coverage.\n\n### 2. Focus on User Impact\nPrioritize errors that directly affect user experience over internal technical issues that users never see.\n\n### 3. Establish Team Workflows\nCreate clear processes for:\n- Who responds to different types of alerts\n- How errors are triaged and prioritized\n- When and how stakeholders are notified\n- How resolution is tracked and verified\n\n### 4. Learn from Patterns\nRegularly review error trends to identify:\n- Common sources of bugs in your codebase\n- Times when errors spike (deployments, high traffic)\n- Features that consistently have issues\n- Opportunities for proactive improvements\n\n### 5. Measure and Improve\nTrack metrics like detection time, resolution time, and user impact to continuously improve your error monitoring effectiveness.\n\n## The Business Value\n\nError monitoring isn't just a technical tool—it's a business enabler:\n\n**Improved User Experience**: Users encounter fewer broken features and faster issue resolution\n**Increased Revenue**: Fewer failed transactions and higher user retention\n**Reduced Support Costs**: Proactive issue detection reduces support ticket volume\n**Faster Development**: Less time spent debugging means more time building features\n**Data-Driven Decisions**: Error patterns inform product and engineering priorities\n\n## Getting Started\n\nThe key to successful error monitoring is starting with clear objectives and gradually building more sophisticated monitoring as your needs grow. Focus on monitoring what matters most to your users and business, and let the insights guide your development priorities.\n\nIn the next lesson, we'll explore how to set up your first error monitoring system and configure it to capture meaningful, actionable data about your application's health.",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.308Z",
    "updatedAt": "2025-06-02T07:03:56.799Z"
  },
  {
    "id": "g026msl4j6oui3ev9p3rs2jm",
    "courseId": "wcja6u9fuk2edvmcvjr16zyd",
    "title": "Core Concepts",
    "slug": "core-concepts",
    "description": "Learn the core concepts and fundamentals",
    "type": "text",
    "content": "# Setting Up Your First Error Monitor\n\n## Planning Your Error Monitoring Setup\n\nBefore diving into implementation, it's important to understand your application's architecture and identify the most critical areas to monitor. A well-planned approach will give you maximum value with minimal complexity.\n\n### Understanding Your Application\n\n**Frontend Applications**\nThese include web browsers, mobile apps, and desktop applications where users directly interact with your software. Frontend errors often manifest as:\n- Broken user interface elements\n- Failed form submissions\n- Navigation issues\n- Performance problems affecting user experience\n\n**Backend Services**\nServer-side applications, APIs, and microservices that power your frontend. Backend errors typically involve:\n- Database connection failures\n- API endpoint crashes\n- Authentication and authorization issues\n- Integration problems with third-party services\n\n**Critical User Journeys**\nIdentify the paths through your application that are most important to your business:\n- User registration and onboarding\n- Payment and subscription processes\n- Core product features\n- Administrative functions\n\n## Choosing an Error Monitoring Solution\n\n### Key Evaluation Criteria\n\n**Ease of Integration**\nLook for solutions that can be implemented quickly without major code changes. The best error monitoring tools integrate with just a few lines of code and automatically capture most common error types.\n\n**Language and Framework Support**\nEnsure your chosen solution supports your technology stack. Most modern error monitoring platforms support popular languages like JavaScript, Python, Java, PHP, and frameworks like React, Angular, Django, and Rails.\n\n**Alerting and Notification Options**\nConsider how your team prefers to receive notifications:\n- Email alerts for non-urgent issues\n- Slack or Microsoft Teams integration for team coordination\n- PagerDuty or Opsgenie for critical production issues\n- Mobile app notifications for on-call engineers\n\n**Data Retention and Pricing**\nUnderstand how long error data is stored and how pricing scales with your application's error volume. Start with conservative estimates and plan for growth.\n\n### Popular Error Monitoring Platforms\n\n**Sentry**\nComprehensive error monitoring with strong community support, excellent documentation, and generous free tiers for small projects.\n\n**Rollbar**\nDeveloper-friendly platform with powerful error grouping and detailed stack traces.\n\n**Bugsnag**\nFocuses on stability monitoring with business impact metrics and release tracking.\n\n**LogRocket**\nCombines error monitoring with session replay for complete user experience visibility.\n\n## Implementation Strategy\n\n### Phase 1: Basic Error Capture\n\nStart with automatic error detection to establish baseline monitoring:\n\n**Unhandled Exceptions**\nThese are errors that occur unexpectedly and aren't caught by your application's error handling code. They represent the most critical issues because they can crash features or entire applications.\n\n**API Failures**\nMonitor external service calls and database queries that might fail due to network issues, service outages, or rate limiting.\n\n**Performance Issues**\nTrack operations that take unusually long to complete, as these often indicate underlying problems.\n\n### Phase 2: Enhanced Context\n\nOnce basic monitoring is working, add contextual information:\n\n**User Information**\nConnect errors to specific users (while respecting privacy) to understand impact and patterns.\n\n**Release Tracking**\nTag errors with deployment versions to quickly identify if new releases introduce problems.\n\n**Custom Metadata**\nAdd business-specific context like feature flags, user segments, or transaction IDs.\n\n### Phase 3: Proactive Monitoring\n\nExpand beyond reactive error detection:\n\n**Custom Error Tracking**\nManually capture business logic errors that don't crash the application but indicate problems.\n\n**Performance Thresholds**\nSet alerts for operations that exceed acceptable performance limits.\n\n**Health Checks**\nMonitor critical system components even when they're not actively generating errors.\n\n## Configuration Best Practices\n\n### Error Filtering and Grouping\n\n**Noise Reduction**\nConfigure your monitoring to ignore errors that don't require action:\n- Browser extension conflicts\n- Network connectivity issues from specific regions\n- Known third-party service limitations\n- Development and testing errors\n\n**Smart Grouping**\nEnsure similar errors are grouped together to prevent alert fatigue:\n- Group by error message and stack trace\n- Consider user actions that led to the error\n- Account for different error contexts (mobile vs. desktop)\n\n### Alert Thresholds\n\n**Start Conservative**\nBegin with higher thresholds to avoid overwhelming your team, then gradually lower them as you understand your application's normal error patterns.\n\n**Consider Business Impact**\nSet more sensitive alerts for errors affecting critical features like payments or user registration.\n\n**Time-Based Rules**\nConfigure different alert sensitivities for business hours vs. after-hours, and weekdays vs. weekends.\n\n### Team Workflows\n\n**Ownership Assignment**\nClearly define who is responsible for different types of errors:\n- Frontend errors to frontend developers\n- API errors to backend teams\n- Infrastructure issues to DevOps\n- Business logic errors to product teams\n\n**Escalation Procedures**\nEstablish clear steps for when issues aren't resolved within acceptable timeframes:\n- Initial alert to primary oncall\n- Escalation to team lead after 30 minutes\n- Manager notification for issues lasting over 2 hours\n- Executive notification for major outages\n\n## Testing Your Setup\n\n### Verification Steps\n\n**Trigger Test Errors**\nIntentionally create errors in a safe environment to verify your monitoring system captures them correctly.\n\n**Check Alert Delivery**\nEnsure notifications reach the right people through the correct channels within acceptable timeframes.\n\n**Validate Error Grouping**\nConfirm that similar errors are properly grouped and that unique issues create separate alerts.\n\n**Review Context Data**\nVerify that captured errors include sufficient information for debugging.\n\n### Common Setup Issues\n\n**Over-Alerting**\nIf you receive too many notifications, review your filtering rules and alert thresholds. It's better to miss some minor issues than to ignore all alerts due to fatigue.\n\n**Under-Alerting**\nIf critical issues aren't generating alerts, check your error capture configuration and ensure you're monitoring the right application components.\n\n**Missing Context**\nErrors without sufficient debugging information should prompt you to add more contextual data capture.\n\n**False Positives**\nAlerts for non-issues indicate a need for better error classification and filtering rules.\n\n## Building Monitoring into Development Workflow\n\n### Development Environment\nSet up error monitoring in development environments to catch issues early, but use separate projects or tags to avoid mixing development noise with production alerts.\n\n### Testing and Staging\nUse pre-production environments to validate that your error monitoring captures issues correctly before they reach users.\n\n### Deployment Integration\nConfigure your deployment process to:\n- Create new releases in your error monitoring system\n- Tag errors with deployment versions\n- Monitor error rates after deployments\n- Automatically rollback if error rates spike\n\n## Measuring Success\n\n### Key Metrics to Track\n\n**Mean Time to Detection (MTTD)**\nHow quickly you become aware of issues after they start affecting users.\n\n**Mean Time to Resolution (MTTR)**\nHow long it takes to fix problems once they're detected.\n\n**Error Rate Trends**\nWhether your overall application stability is improving over time.\n\n**User-Reported vs. System-Detected Issues**\nThe ratio of problems you catch proactively versus those reported by frustrated users.\n\n### Continuous Improvement\n\n**Regular Reviews**\nWeekly or monthly review sessions to:\n- Analyze error patterns and trends\n- Adjust alert thresholds and filters\n- Identify opportunities for prevention\n- Update team processes and procedures\n\n**Feedback Loops**\nCollect input from developers about the usefulness of error information and adjust configuration to provide better debugging context.\n\n**Integration Expansion**\nAs your team becomes comfortable with basic error monitoring, consider integrating with other tools like performance monitoring, logging systems, and customer support platforms.\n\n## Common Pitfalls to Avoid\n\n**Monitoring Everything at Once**\nStart focused and expand gradually rather than trying to monitor every possible error from day one.\n\n**Ignoring Alert Fatigue**\nIf your team starts ignoring alerts, the entire system becomes useless. Regularly tune your configuration to maintain signal-to-noise ratio.\n\n**Focusing Only on Technical Metrics**\nRemember that the goal is improving user experience and business outcomes, not just reducing error counts.\n\n**Neglecting Team Training**\nEnsure everyone on your team understands how to interpret error reports and follow established response procedures.\n\nSetting up effective error monitoring is an iterative process. Start with basic coverage of your most critical features, learn from the data you collect, and gradually build more sophisticated monitoring as your needs and understanding grow.\n\nIn our next lesson, we'll explore how to analyze error data to identify patterns, prioritize fixes, and prevent future issues.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.380Z",
    "updatedAt": "2025-06-02T07:03:56.876Z"
  },
  {
    "id": "ik1bwa3ebzzncx2qvekje46m",
    "courseId": "wcja6u9fuk2edvmcvjr16zyd",
    "title": "Practical Implementation",
    "slug": "practical-implementation",
    "description": "Hands-on implementation and best practices",
    "type": "text",
    "content": "# Error Context and Debugging Information\n\n## The Power of Context in Error Resolution\n\nWhen an error occurs in production, the error message itself is often just the tip of the iceberg. What happened before the error? What was the user trying to accomplish? What was the state of the application? These contextual details make the difference between spending hours hunting for bugs and quickly identifying and fixing issues.\n\n## Understanding Error Context\n\n### Technical Context\n\n**Stack Traces**\nThe sequence of function calls that led to an error. Think of it as a breadcrumb trail showing exactly how your application arrived at the problematic code. A good stack trace shows:\n- The specific line of code where the error occurred\n- The function calls that led to that point\n- The files and modules involved in the execution path\n\n**Environment Information**\nDetails about the runtime environment help identify if errors are specific to certain conditions:\n- Operating system and version\n- Browser type and version\n- Device type (mobile, tablet, desktop)\n- Screen resolution and available memory\n- Network connection quality\n\n**Application State**\nThe condition of your application when the error occurred:\n- Current page or feature being used\n- Form data or user inputs\n- Authentication status\n- Active feature flags or configuration settings\n\n### User Context\n\n**User Journey**\nUnderstanding what the user was trying to accomplish provides crucial insight into error impact and urgency:\n- Navigation path leading to the error\n- Previous actions taken in the session\n- Time spent on different pages\n- Attempted interactions before the failure\n\n**User Characteristics**\nDemographic and behavioral information helps identify patterns:\n- User type (new vs. returning)\n- Geographic location\n- Language and locale settings\n- Subscription or account level\n- Previous support interactions\n\n**Session Information**\nDetails about the user's current session:\n- Session duration\n- Number of page views\n- Other errors in the same session\n- Performance metrics for the session\n\n### Business Context\n\n**Feature Impact**\nUnderstanding which business features are affected helps prioritize fixes:\n- Revenue-generating features (payments, subscriptions)\n- Core product functionality\n- User onboarding and engagement features\n- Administrative and support tools\n\n**Customer Impact**\nAssessing the business consequences of errors:\n- Number of affected users\n- Potential revenue loss\n- Support ticket generation\n- Customer satisfaction implications\n\n## Types of Debugging Information\n\n### Breadcrumbs\n\nBreadcrumbs are a chronological trail of events leading up to an error. They provide crucial context about user behavior and application flow:\n\n**User Actions**\n- Button clicks and form submissions\n- Page navigation and routing changes\n- Search queries and filter applications\n- File uploads or downloads\n\n**System Events**\n- API calls and database queries\n- Authentication attempts\n- Cache hits and misses\n- Background job executions\n\n**Performance Markers**\n- Page load times\n- Network request durations\n- Database query performance\n- Memory usage changes\n\n### Custom Tags and Metadata\n\n**Business Logic Tags**\n- Feature flags and experiment variants\n- User segments and cohorts\n- Product categories or types\n- Workflow stages or process steps\n\n**Technical Tags**\n- Service versions and build numbers\n- Database cluster or region\n- CDN or server locations\n- Third-party service versions\n\n### Release and Deployment Context\n\n**Version Tracking**\nConnecting errors to specific code releases helps identify when problems were introduced:\n- Application version numbers\n- Git commit hashes\n- Deployment timestamps\n- Feature rollout percentages\n\n**Environment Information**\nUnderstanding deployment context:\n- Production vs. staging environments\n- Server regions and availability zones\n- Infrastructure versions (Node.js, Python, etc.)\n- Database schema versions\n\n## Effective Error Grouping\n\n### Smart Aggregation\n\n**Similarity Detection**\nModern error monitoring systems group similar errors to prevent alert fatigue:\n- Stack trace fingerprinting\n- Error message pattern matching\n- User action sequence analysis\n- Environment characteristic clustering\n\n**Impact Assessment**\nGrouping helps understand the scope of issues:\n- Total number of affected users\n- Geographic distribution of errors\n- Time patterns and trends\n- Device and browser distribution\n\n### Custom Grouping Rules\n\n**Business Logic Grouping**\nSometimes technical similarity doesn't match business impact:\n- Group by affected feature or workflow\n- Separate errors by user type or subscription level\n- Distinguish between error severity levels\n- Account for different error contexts\n\n## Prioritization Strategies\n\n### Severity Assessment\n\n**User Impact Severity**\n- **Critical**: Prevents core functionality, affects payments\n- **High**: Degrades important features, affects many users\n- **Medium**: Minor feature issues, affects some users\n- **Low**: Cosmetic issues, affects few users\n\n**Business Impact Priority**\n- Revenue-affecting errors get highest priority\n- User experience issues prioritized by affected user count\n- New feature errors evaluated against rollout goals\n- Legacy feature errors assessed against maintenance costs\n\n### Resource Allocation\n\n**Team Expertise Matching**\nRoute errors to teams with relevant expertise:\n- Frontend errors to UI/UX teams\n- API errors to backend developers\n- Performance issues to infrastructure teams\n- Business logic errors to product teams\n\n**Workload Balancing**\nConsider current team capacity and competing priorities:\n- Critical production issues always take precedence\n- Schedule non-urgent fixes during regular sprint planning\n- Balance bug fixes with new feature development\n- Account for team member availability and expertise\n\n## Building Effective Debugging Workflows\n\n### Initial Triage\n\n**Rapid Assessment**\nQuick evaluation to determine immediate action needed:\n- Is this affecting active users right now?\n- Is this a new issue or recurring problem?\n- Do we have enough information to investigate?\n- Who is the right person to investigate?\n\n**Information Gathering**\nCollect additional context if needed:\n- Check related system metrics\n- Review recent deployments or changes\n- Examine user feedback and support tickets\n- Verify error frequency and trends\n\n### Investigation Process\n\n**Hypothesis Formation**\nUse available context to form theories about root causes:\n- Recent code changes that might be related\n- Known issues with similar symptoms\n- Environmental factors that could contribute\n- User behavior patterns that might trigger the error\n\n**Reproduction Attempts**\nTry to recreate the error in controlled environments:\n- Use the same browser and device type\n- Follow the user's navigation path\n- Input similar data or interactions\n- Test under similar network conditions\n\n### Resolution Documentation\n\n**Root Cause Analysis**\nDocument findings for future reference:\n- What caused the error?\n- Why wasn't it caught earlier?\n- What conditions must exist for it to occur?\n- How can similar issues be prevented?\n\n**Fix Validation**\nConfirm that solutions actually resolve the problem:\n- Test fixes in staging environments\n- Monitor error rates after deployment\n- Verify user experience improvements\n- Check for any unintended side effects\n\n## Learning from Error Patterns\n\n### Trend Analysis\n\n**Temporal Patterns**\nLook for time-based trends in error occurrence:\n- Errors that spike during high-traffic periods\n- Issues that appear after deployments\n- Problems that correlate with external events\n- Seasonal or cyclical error patterns\n\n**Code Quality Insights**\nUse error patterns to improve development practices:\n- Files or modules with frequent errors\n- Types of coding mistakes that recur\n- Testing gaps that allow bugs to reach production\n- Architecture patterns that are error-prone\n\n### Prevention Strategies\n\n**Proactive Monitoring**\nUse error context to set up better monitoring:\n- Add health checks for commonly failing components\n- Monitor leading indicators that predict errors\n- Set up alerts for unusual user behavior patterns\n- Track performance metrics that correlate with errors\n\n**Development Process Improvements**\nApply lessons learned to prevent future issues:\n- Add automated tests for common error scenarios\n- Improve code review processes to catch error-prone patterns\n- Enhance staging environments to better match production\n- Update deployment practices to reduce error-inducing changes\n\n## Best Practices for Maximizing Context Value\n\n### Balance Detail with Performance\nCollect comprehensive context without significantly impacting application performance. Focus on high-value information that aids debugging while minimizing data collection overhead.\n\n### Respect User Privacy\nEnsure that contextual information collection complies with privacy regulations and user expectations. Avoid capturing sensitive personal information and provide clear opt-out mechanisms.\n\n### Regularly Review and Refine\nContinuously evaluate the usefulness of collected context. Remove data that isn't helping with debugging and add new context that would improve investigation efficiency.\n\n### Train Your Team\nEnsure all team members understand how to interpret and utilize error context effectively. Regular training on debugging techniques and context analysis improves overall team efficiency.\n\n## Measuring Context Effectiveness\n\nTrack metrics that indicate whether your error context is helping achieve faster resolution:\n- Time from error detection to root cause identification\n- Percentage of errors resolved without additional investigation\n- Reduction in back-and-forth communication during debugging\n- Developer satisfaction with available debugging information\n\nEffective error context transforms reactive firefighting into proactive problem-solving. By capturing the right information at the right time, your team can quickly understand not just what went wrong, but why it went wrong and how to prevent similar issues in the future.\n\nThe goal isn't to capture every possible piece of information, but to thoughtfully collect the context that enables fast, accurate debugging and drives continuous improvement in application reliability.",
    "videoUrl": null,
    "duration": "45 min",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-02T06:34:16.451Z",
    "updatedAt": "2025-06-02T07:03:56.946Z"
  },
  {
    "id": "fuc0m7lhwkd52kbmv4shox09",
    "courseId": "o4cldqvl7f9dfktejzgju240",
    "title": "What is Tracing?",
    "slug": "what-is-tracing",
    "description": "Introduction to tracing concepts and why they matter for modern applications.",
    "type": "text",
    "content": "# What is Tracing?\n\nThis lesson will cover the fundamental concepts of tracing...",
    "videoUrl": null,
    "duration": "30 min",
    "order": 1,
    "isFree": true,
    "resources": [],
    "createdAt": "2025-06-04T16:44:33.831Z",
    "updatedAt": "2025-06-04T16:44:33.831Z"
  },
  {
    "id": "eadbxyg8xqm0cbccdroaarqt",
    "courseId": "o4cldqvl7f9dfktejzgju240",
    "title": "Setting Up Basic Tracing",
    "slug": "setting-up-basic-tracing",
    "description": "Configure simple tracing for your applications to start collecting data.",
    "type": "text",
    "content": "# Setting Up Basic Tracing\n\nLearn how to implement basic tracing in your applications...",
    "videoUrl": null,
    "duration": "1 hour",
    "order": 2,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-04T16:44:33.939Z",
    "updatedAt": "2025-06-04T16:44:33.939Z"
  },
  {
    "id": "f3p91nsa5s7hk4h279rymt89",
    "courseId": "o4cldqvl7f9dfktejzgju240",
    "title": "Understanding Trace Data",
    "slug": "understanding-trace-data",
    "description": "Learn to read and interpret trace data to identify performance issues.",
    "type": "text",
    "content": "# Understanding Trace Data\n\nMaster the art of reading and analyzing trace data...",
    "videoUrl": null,
    "duration": "1.5 hours",
    "order": 3,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-04T16:44:34.001Z",
    "updatedAt": "2025-06-04T16:44:34.001Z"
  },
  {
    "id": "psnvzti8sc0dp1iw223la2da",
    "courseId": "o4cldqvl7f9dfktejzgju240",
    "title": "Basic Trace Visualization",
    "slug": "basic-trace-visualization",
    "description": "Using trace visualization tools to understand your application flow.",
    "type": "text",
    "content": "# Basic Trace Visualization\n\nLearn how to use visualization tools to understand your traces...",
    "videoUrl": null,
    "duration": "1 hour",
    "order": 4,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-04T16:44:34.064Z",
    "updatedAt": "2025-06-04T16:44:34.064Z"
  },
  {
    "id": "d11ylsknoy694r2v7w9j66hh",
    "courseId": "o4cldqvl7f9dfktejzgju240",
    "title": "Common Tracing Patterns",
    "slug": "common-tracing-patterns",
    "description": "Learn about common tracing patterns and best practices for beginners.",
    "type": "text",
    "content": "# Common Tracing Patterns\n\nExplore common patterns and best practices in tracing...",
    "videoUrl": null,
    "duration": "1.5 hours",
    "order": 5,
    "isFree": false,
    "resources": [],
    "createdAt": "2025-06-04T16:44:34.136Z",
    "updatedAt": "2025-06-04T16:44:34.136Z"
  }
]